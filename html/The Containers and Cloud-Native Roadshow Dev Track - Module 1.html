<!DOCTYPE html>
<html><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><style type="text/css">.turbolinks-progress-bar {
  position: fixed;
  display: block;
  top: 0;
  left: 0;
  height: 3px;
  background: #0076ff;
  z-index: 9999;
  transition: width 300ms ease-out, opacity 150ms 150ms ease-in;
  transform: translate3d(0, 0, 0);
}</style>
  
  

  <link rel="stylesheet" media="all" href="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/application-dcf5640dabe7c086c5db76b2e378b4def3309902bc32af61.css" data-turbolinks-track="reload">
  <script src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/application-1763c4134299cf1911a383dd8d9b23b574b429196c500fbba.js" data-turbolinks-track="reload"></script><style type="text/css">/* Chart.js */
@-webkit-keyframes chartjs-render-animation{from{opacity:0.99}to{opacity:1}}@keyframes chartjs-render-animation{from{opacity:0.99}to{opacity:1}}.chartjs-render-monitor{-webkit-animation:chartjs-render-animation 0.001s;animation:chartjs-render-animation 0.001s;}</style>
<title>
      The Containers and Cloud-Native Roadshow Dev Track - Module 1
  </title><meta name="csrf-param" content="authenticity_token"><meta name="csrf-token" content="CIB9qCt+VpfbOLrkVOt7555QeP7UlExRxrLrbBEkboZdEj8eOKZy7otWH4WK3lm0s7AgHYpiVMEeMzZXZx4KSw=="></head>

<body>
<nav class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark">
  <div class="container-fluid d-flex justify-content-start">
    <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarContent">
      <span class="navbar-toggler-icon"></span>
    </button>
      <a class="navbar-brand mb-0 h1" href="http://guides-m1-labs-infra.apps.cluster-tokyo-069d.tokyo-069d.open.redhat.com/workshop/cloudnative" id="workshopName">The Containers and Cloud-Native Roadshow Dev Track - Module 1</a>
  </div>
</nav>

<script type="application/javascript">
    if (App.hasOwnProperty('subscription_id')) {
        App.cable.subscriptions.remove(App.subscription_id);
    }

    App.subscription_id = App.report_page_view('cloudnative#complete', 'f8ebfef8-5794-4a17-be2c-4dde6a85cb2e');
</script>

<main class="container-fluid">
  <div class="row">
    <div class="col-md-12">
        <h2>Your Workshop Environment</h2>
        <h2 id="the-workshop-environment-you-are-using">The Workshop Environment You Are Using</h2>

<p>Your workshop environment consists of several components which have 
been pre-installed and are ready to use. Depending on which parts of the
 workshop you’re doing, you will use one or more of:</p>

<ul>
  <li><a href="https://www.openshift.com/" target="_blank">Red Hat OpenShift</a> - You’ll use one or more <em>projects</em> (Kubernetes namespaces) that are your own and are isolated from other workshop students</li>
  <li><a href="https://developers.redhat.com/products/codeready-workspaces/overview" target="_blank">Red Hat CodeReady Workspaces</a> - based on <strong>Eclipse Che</strong>,
 it’s a cloud-based, in-browser IDE (similar to IntelliJ IDEA, VSCode, 
Eclipse IDE). You’ve been provisioned your own personal workspace for 
use with this workshop. You’ll write, test, and deploy code from here.</li>
  <li><a href="https://developers.redhat.com/products/rhamt" target="_blank">Red Hat Application Migration Toolkit</a> - You’ll use this to migrate an existing application</li>
  <li><a href="https://www.redhat.com/en/products/runtimes" target="_blank">Red Hat Runtimes</a> - a collection of cloud-native runtimes like Spring Boot, Node.js, and <a href="https://quarkus.io/" target="_blank">Quarkus</a></li>
  <li><a href="https://www.redhat.com/en/technologies/jboss-middleware/amq" target="_blank">Red Hat AMQ Streams</a> - streaming data platform based on <strong>Apache Kafka</strong></li>
  <li><a href="https://access.redhat.com/products/red-hat-single-sign-on" target="_blank">Red Hat SSO</a> - For authentication / authorization - based on <strong>Keycloak</strong></li>
  <li>Other open source projects like <a href="https://gogs.io/" target="_blank">Gogs</a> (Git server that holds application source code), <a href="https://knative.dev/" target="_blank">Knative</a> (for serverless apps), <a href="https://jenkins.io/" target="_blank">Jenkins</a> and <a href="https://cloud.google.com/tekton/" target="_blank">Tekton</a> (CI/CD pipelines), <a href="https://prometheus.io/" target="_blank">Prometheus</a> and <a href="https://grafana.com/" target="_blank">Grafana</a> (monitoring apps), and more.</li>
</ul>

<p>You’ll be provided clickable URLs throughout the workshop to access the services that have been installed for you.</p>

<h2 id="how-to-complete-this-workshop">How to complete this workshop</h2>

<p>Simply follow these instructions end-to-end. <strong>You’ll need to do quite a bit of copy/paste for Linux commands and source code modifications</strong>,
 as well as clicking around on various consoles used in the labs. When 
you get to the end of each section, you can click the “Next &gt;” button
 at the bottom to advance to the next topic. You can also use the menu 
on the left to move around the instructions at will.</p>

<p>The entire workshop is split into one or more <em>modules</em> - Look
 at the top of the screen in the header to see which module you are on. 
After you complete this module, your instructor may have additional 
modules to complete.</p>

<p>Good luck, and let’s get started!</p>

        <hr>
        <h2>Getting Started with Cloud-Native Apps</h2>
        <h2 id="getting-started-with-cloud-native-apps">Getting Started with Cloud-Native Apps</h2>

<p>In this module you’ll work with an existing Java EE application for a
 retail webshop and migrate it and modernize it.
The current version of the webshop is a Java EE application built for 
Oracle Weblogic Application Server and as part of a modernization 
strategy and to be able to automate releases and eventually apply 
advanced deployment scenarios (like Canary or Blue/Green deployments) 
there has been a decision to move this application to a container native
 environment from Red Hat called OpenShift.</p>

<p>During the first planning sprint you have investigated the 
possibility to deploy Oracle Weblogic to Red Hat OpenShift, but since 
Oracle Weblogic is limited in support and also not recommended to use in
 an orchestrated container native platform like OpenShift you have two 
options. Either you migrate to WebSphere Liberty Profile or you migrate 
to JBoss EAP.</p>

<table>
  <thead>
    <tr>
      <th>Charateristics</th>
      <th>Oracle Weblogic</th>
      <th>JBoss EAP</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Supported on OpenShift</td>
      <td>Limited</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Supports Java EE 8 Web Profile</td>
      <td>Yes</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Supports Java EE 8</td>
      <td>Yes</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Has an S2I build image</td>
      <td>No</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Has a container image that is supported by the vendor</td>
      <td>No</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Autoconfiguration of data sources and messaging</td>
      <td>No</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Autoconfiguration of SSO</td>
      <td>No</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Capable of handling transaction recovery in an ephemeral container</td>
      <td>Unknown</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Adapted for clustering in Kubernetes (session failover, etc)</td>
      <td>No</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Single vendor support</td>
      <td>Yes</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Support and maintenance cost</td>
      <td>High</td>
      <td>Included</td>
    </tr>
    <tr>
      <td>Migration effort</td>
      <td>High</td>
      <td>Low</td>
    </tr>
  </tbody>
</table>

<p>After the investigation the team agrees that JBoss EAP seems to be 
the much better choice with better support for running your application 
in OpenShift, but the last question mark on “Migration cost” is 
worrying. You decide to contact Red Hat to try to find out what the 
migration cost might actually be. Red Hat uses a tool called Red Hat 
Application Migration Toolkit (RHAMT) which help customers analyze their
 applications and report on the estimated effort to migrate and also 
provides detailed instructions on how to actually migrate the code.</p>

<h4 id="what-is-red-hat-application-migration-toolkit">What is Red Hat Application Migration Toolkit?</h4>

<hr>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/rhamt_logo.dms" alt="RHAMT Logo"></p>

<p>Red Hat Application Migration Toolkit (RHAMT) is an extensible and 
customizable rule-based tool that helps simplify migration of Java 
applications.</p>

<p>It is used by organizations for:</p>

<ul>
  <li>Planning and work estimation</li>
  <li>Identifying migration issues and providing solutions</li>
  <li>Detailed reporting</li>
  <li>Using built-in rules and migration paths</li>
  <li>Rule extension and customizability</li>
  <li>Ability to analyze source code or application archives</li>
</ul>

<p>RHAMT examines application artifacts, including project source 
directories and application archives, then produces an HTML report that 
highlights areas needing changes. RHAMT can be used to migrate Java 
applications from previous versions of Red Hat JBoss Enterprise 
Application Platform or from other middleware, such as Oracle® WebLogic 
Server or IBM® WebSphere® Application Server.</p>

<h4 id="how-does-red-hat-application-migration-toolkit-simplify-migration">How Does Red Hat Application Migration Toolkit Simplify Migration?</h4>

<hr>

<p>Red Hat Application Migration Toolkit looks for common resources and 
highlights technologies and known trouble spots when migrating 
applications. The goal is to provide a high-level view into the 
technologies used by the application and provide a detailed report 
organizations can use to estimate, document, and carry out migration of 
enterprise applications to Java EE and Red Hat JBoss Enterprise 
Application Platform.</p>

<blockquote>
  <p>RHAMT is usually part of a much larger application migration and 
modernization program that involves well defined and repeatable phases 
over weeks or months and involves many people from a given business. Do 
not be fooled into thinking that every single
migration is a simple affair and takes an hour or less! To learn more 
about Red Hat’s philosophy and proven methodology, check out
the <a href="https://access.redhat.com/documentation/en/red-hat-application-migration-toolkit" target="_blank">RHAMT documentation</a> and contact your local Red Hat representative when embarking on a real world migration and modernization strategy.</p>
</blockquote>

<h5 id="more-rhamt-resources">More RHAMT Resources</h5>

<ul>
  <li><a href="https://access.redhat.com/documentation/en/red-hat-application-migration-toolkit" target="_blank">Documentation</a></li>
  <li><a href="https://developers.redhat.com/products/rhamt/overview/" target="_blank">Developer Homepage</a></li>
</ul>

<h4 id="what-comes-after-migration">What comes after migration?</h4>

<hr>

<p>You might wonder about developing <strong>new</strong> cloud-native apps once you complete your migration of existing apps via RHAMT.</p>

<p>Red Hat Runtimes provides a curated, best-of-breed collection of 
cloud native runtimes that let you match application requirements to the
 best runtime, and allows your organization to standardize on a set of 
runtimes to support the business. Fully supported runtimes include:</p>

<ul>
  <li><a href="https://spring.io/projects/spring-boot" target="_blank">Spring Boot</a> - Create stand-alone, production-grade Spring based Applications that you can “just run”.</li>
  <li><a href="https://nodejs.org/en/" target="_blank">Node.Js</a> - A 
JavaScript runtime built on Chrome’s V8 JavaScript engine, using an 
event-driven, non-blocking I/O model for lightweight efficiency.</li>
  <li><a href="https://quarkus.io/" target="_blank">Quarkus</a> - A 
Kubernetes Native Java stack tailored for GraalVM and OpenJDK HotSpot, 
crafted from the best of breed Java libraries and standards</li>
  <li><a href="https://thorntail.io/" target="_blank">MicroProfile</a> -
 Thorntail, a MicroProfile implementation, allows you to develop Java 
microservices, packaging them with just enough of the server runtime to <code>java -jar</code> your application.</li>
  <li><a href="https://projects.eclipse.org/projects/rt.vertx" target="_blank">Eclipse Vert.x</a> - A tool-kit for building reactive applications on the JVM.</li>
</ul>

<p>We will use several of these runtimes during the course of this 
workshop. After this workshop you can try these on your own using our <a href="https://learn.openshift.com/middleware/">self-paced, in-browser learning guides</a>.</p>

<p>Let’s get started!</p>

        <hr>
        <h2>Decide which Application Server to use in OpenShift</h2>
        <h2 id="lab1---decide-which-application-server-to-use-in-openshift">Lab1 - Decide which Application Server to use in OpenShift</h2>

<p>In this step we will analyze a monolithic application built for use 
with Oracle® WebLogic Server (WLS). This application is a Java EE 
application
using a number of different technologies, including standard Java EE 
APIs as well as proprietary Weblogic APIs and best practices.</p>

<p>The Red Hat Application Migration Toolkit can be installed and used in a few different ways:</p>

<ul>
  <li><code>Web Console</code> - The web console for Red Hat Application
 Migration Toolkit is a web-based system that allows a team of users to 
assess and prioritize migration and modernization efforts for a large 
number of applications. It allows you to group applications into 
projects for analysis and provides numerous reports that highlight the 
results.</li>
  <li><code>Command Line Interface</code> - The CLI is a command-line 
tool that allows users to assess and prioritize migration and 
modernization efforts for applications. It provides numerous reports 
that highlight the analysis results.</li>
  <li><code>Eclipse Plugin</code> - The Eclipse plugin for Red Hat 
Application Migration Toolkit provides assistance directly in Eclipse 
and Red Hat JBoss Developer Studio for developers making changes for a 
migration or modernization effort. It analyzes your projects using 
RHAMT, marks migration issues in the source code, provides guidance to 
fix the issues, and offers automatic code replacement when possible.</li>
</ul>

<p>For this lab, we will use the Web Console on top of OpenShift Container Platform.</p>

<h4 id="login-the-rhamt-web-console-in-openshift-cluster">1. Login the RHAMT web console in OpenShift cluster</h4>

<hr>

<p>To get started, <a href="http://rhamt-web-console-labs-infra.apps.cluster-tokyo-069d.tokyo-069d.open.redhat.com/" target="_blank">access the Red Hat Application Migration Toolkit</a> and log in using the username and password you’ve been assigned (e.g. <code>userXX/r3dh4t1!</code>):</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/rhamt_login.dms" alt="RHAMT Login"></p>

<p>When you login the first time, you should be asked to change the password in order to comply with RH SSO policy.</p>

<blockquote>
  <p><code>NOTE</code>: You can use the current password to input a new password.</p>
</blockquote>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/rhamt_change_pwd.dms" alt="RHAMT Change Pwd"></p>

<h4 id="create-a-new-project">2. Create a new project</h4>

<hr>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/rhamt_landing_page.dms" alt="RHAMT Landing Page"></p>

<p>Input a name and description to create a project.</p>

<ul>
  <li>Name: <code>userXX-eap-migration</code></li>
  <li>Description: <code>USERXX EAP MIGRATION PROJECT</code></li>
</ul>

<blockquote>
  <p><code>NOTE</code>: Add your username as prefix (i.e. <code>user1-eap-migration</code>) to distinguish each attendee’s project.</p>
</blockquote>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/rhamt_create_project.dms" alt="RHAMT Create Project"></p>

<h4 id="add-the-monolith-application-to-the-project">3. Add the monolith application to the project</h4>

<hr>

<p>Select <code>Server Path</code> to analyze a monolithic application:</p>

<ul>
  <li>Server Path: <code>/opt/apps</code></li>
</ul>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/rhamt_add_monolith_app1.dms" alt="RHAMT Add App"></p>

<h4 id="select-migration-to-jboss-eap-7-in-transformation-path">4. Select “Migration to JBoss EAP 7” in Transformation Path</h4>

<hr>

<p>Choose the <code>com</code> and <code>weblogic</code> checkboxes to include these packages during analysis and click the <code>Save &amp; Run</code> button. You will be taken to Analysis Results dashboard page, wait until the analysis is complete.</p>

<ul>
  <li>Check <code>com, weblogic</code> for Included packages.</li>
</ul>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/rhamt_check_monolith_app.dms" alt="RHAMT Add App"></p>

<p><code>Tip</code>: This page may look just like an OpenShift console 
page, its not, its the Red Hat Application Migration Toolkit console - 
both project use <a href="https://www.patternfly.org/" target="_blank">PatternFly</a> for a consistent web look and feel.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/rhamt_check_monolith_app.dms" alt="RHAMT Add App"></p>

<ul>
  <li>Click <code>Save &amp; Run</code></li>
</ul>

<h4 id="go-to-the-active-analysis-page-and-click-on-the-latest-when-its-completed">5. Go to the Active Analysis page and click on the latest when it’s completed</h4>

<hr>

<p>**Click the <code>#1</code> link (or <code>#2</code>) to see the report:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/rhamt_complete_analysis.dms" alt="RHAMT Complete"></p>

<h4 id="review-the-report">6. Review the report</h4>

<hr>

<p>You should see the landing page for the report:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/rhamt_result_landing_page.dms" alt="RHAMT Langing Page"></p>

<p>The main landing page of the report lists the applications that were 
processed. Each row contains a high-level overview of the story points, 
number of incidents, and technologies encountered in that application.</p>

<p>Click on the <code>monolith.war</code> link to access details for the project:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/rhamt_project_overview.dms" alt="RHAMT Project Overview"></p>

<h4 id="understanding-the-report">7. Understanding the report</h4>

<hr>

<p>The Dashboard gives an overview of the entire application migration effort. It summarizes:</p>

<ul>
  <li>The incidents and story points by category</li>
  <li>The incidents and story points by level of effort of the suggested changes</li>
  <li>The incidents by package</li>
</ul>

<blockquote>
  <p>Story points are an abstract metric commonly used in Agile software
 development to estimate the relative level of effort needed to 
implement a feature or change.
Red Hat Application Migration Toolkit uses story points to express the 
level of effort needed to migrate particular application constructs, and
 the application as
a whole. The level of effort will vary greatly depending on the size and
 complexity of the application(s) to migrate.</p>
</blockquote>

<p>There are several other sub-pages accessible by the menu near the 
top. Click on each one and observe the results for each of these pages:</p>

<ul>
  <li><code>All Applications</code> Provides a list of all applications scanned.</li>
  <li><code>Dashboard</code> Provides an overview for a specific application.</li>
  <li><code>Issues</code> Provides a concise summary of all issues that require attention.</li>
  <li><code>Application Details</code> provides a detailed overview of all resources found within the application that may need attention during the migration.</li>
  <li><code>Unparsable</code> shows all files that RHAMT could not parse
 in the expected format. For instance, a file with a .xml or .wsdl 
suffix is assumed to be an XML file. If the XML parser fails, the issue 
is reported here and also where the individual file is listed.</li>
  <li><code>Dependencies</code> displays all Java-packaged dependencies found within the application.</li>
  <li><code>Remote Services</code> Displays all remote services references that were found within the application.</li>
  <li><code>EJBs</code> contains a list of EJBs found within the application.</li>
  <li><code>JBPM</code> contains all of the JBPM-related resources that were discovered during analysis.</li>
  <li><code>JPA</code> contains details on all JPA-related resources that were found in the application.</li>
  <li><code>About</code> Describes the current version of RHAMT and provides helpful links for further assistance.</li>
</ul>

<blockquote>
  <p>Some of the above sections may not appear depending on what was detected in the project.</p>
</blockquote>

<p>You also investigate the report to see if there are any complex migrations.</p>

<p>After analysing the results and the effort you can estimate the 
amount of time the effort to migrate your application. In this case you 
may estimate that given the 24 story points and that most of the changes
 are trivial the effort will be approximately a week, which is about the
 same time it would take to migration from Oracle Weblogic to WebSphere 
Liberty Profile. You may feel comfortable to claim <code>Low Migration effort</code>
 for this app when you present your recommendation to the team and the 
architectural board. As a result, let us assume today that your 
recommendation to migrate to JBoss EAP to deploy your application on 
OpenShift is approved.</p>

<p>For the first sprint you will focus on migrating the application to 
JBoss EAP, the DBA will migrate the database to a PostgresQL instance on
 OpenShift while the ops engineer setup a project for you in the 
OpenShift cluster.</p>

        <hr>
        <h2>Migrate to JBoss EAP</h2>
        <h2 id="lab2---migrate-your-application-to-jboss-eap">Lab2 - Migrate your application to JBoss EAP</h2>

<p>In this step you will migrate some Weblogic-specific code in the app to use standard Java EE interfaces.</p>

<h4 id="getting-ready-for-the-labs">1. Getting Ready for the labs</h4>

<hr>

<h5 id="access-your-development-environment">Access Your Development Environment</h5>

<p>You will be using Red Hat CodeReady Workspaces, an online IDE based on <a href="https://www.eclipse.org/che/" target="_blank">Eclipe Che</a>. <strong>Changes to files are auto-saved every few seconds</strong>, so you don’t need to explicitly save changes.</p>

<p>To get started, <a href="http://codeready-labs-infra.apps.cluster-tokyo-069d.tokyo-069d.open.redhat.com/" target="_blank">access the Che instance</a> and log in using the username and password you’ve been assigned (e.g. <code>userXX/r3dh4t1!</code>):</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/che-login.dms" alt="cdw"></p>

<p>Once you log in, you’ll be placed on your personal dashboard. We’ve 
pre-created workspaces for you to use. Click on the name of the 
pre-created workspace on the left, as shown below (the name will be 
different depending on your assigned number). You can also click on the 
name of the workspace in the center, and then click on the green button 
that says “OPEN” on the top right hand side of the screen:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/che-precreated.dms" alt="cdw"></p>

<p>After a minute or two, you’ll be placed in the workspace:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/che-workspace.dms" alt="cdw"></p>

<blockquote>
  <p><strong>NOTE</strong>:</p>

  <p>You may see random errors about websocket connections, plugins failing to load or other errors in the <code>dev-machine</code> window. You can ignore them as these are known issues that do not affect this workshop.</p>
</blockquote>

<p>To gain extra screen space, click on the yellow arrow to hide the left menu (you won’t need it):</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/che-realestate.dms" alt="cdw"></p>

<p>Users of Eclipse, IntelliJ IDEA or Visual Studio Code will see a 
familiar layout: a project/file browser on the left, a code editor on 
the right, and a terminal at the bottom. You’ll use all of these during 
the course of this workshop, so keep this browser tab open throughout. <strong>If things get weird, you can simply reload the browser tab to refresh the view.</strong></p>

<p>In the project explorer pane, click on the <code>Import Projects...</code> and enter the following:</p>

<ul>
  <li>Version Control System: <code>GIT</code></li>
  <li>URL: <code>http://gogs-labs-infra.apps.cluster-tokyo-069d.tokyo-069d.open.redhat.com/userXX/cloud-native-workshop-v2m1-labs.git</code>(IMPORTANT: replace userXX with your lab user)</li>
  <li>Check <code>Import recursively (for multi-module projects)</code></li>
  <li>Name: <code>cloud-native-workshop-v2m1-labs</code></li>
</ul>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/codeready-workspace-import.dms" alt="codeready-workspace-import" width="700px"></p>

<p>At the next screen, leave the project type set to <code>Blank</code> and click <strong>Save</strong>.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/codeready-workspace-import-save.dms" alt="codeready-workspace-import-save" width="700px"></p>

<p>The project is imported into your workspace and is visible in the project explorer.</p>

<h3 id="convert-projects">Convert Projects</h3>

<p>Expand the top-level project and look carefully at the icons next to each of the <code>monolith</code>, <code>catalog</code> and <code>inventory</code> directories. <strong>Do you see a blue Maven icon as shown below?</strong></p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/maven-icon.dms" alt="maven-icon" width="900px"></p>

<p>If you do <strong>not</strong> see these icons, then you’ll need to 
right-click on each of the projects, and select “Convert to Project” and
 convert them to the <em>Maven</em> type project as shown below:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/codeready-workspace-convert.dms" alt="codeready-workspace-convert" width="500px"></p>

<p>Choose <strong>Maven</strong> from the project configurations and then click on <strong>Save</strong>.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/codeready-workspace-maven.dms" alt="codeready-workspace-maven" width="700px"></p>

<p>Be sure to do this for each of the <code>monolith</code>, <code>inventory</code> and <code>catalog</code> projects.</p>

<blockquote>
  <p><code>NOTE</code>: the Terminal window in CodeReady Workspaces. For
 the rest of these labs, anytime you need to run a command in a 
terminal, you can use the CodeReady Workspaces Terminal window.</p>
</blockquote>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/codeready-workspace-terminal.dms" alt="codeready-workspace-terminal"></p>

<h4 id="review-the-issue-related-to-applicationlifecyclelistener">2. Review the issue related to <code>ApplicationLifecycleListener</code></h4>

<hr>

<p>Open the Issues report in the <a href="http://rhamt-web-console-labs-infra.apps.cluster-tokyo-069d.tokyo-069d.open.redhat.com/" target="_blank">RHAMT Console</a>:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/rhamt_project_issues.dms" alt="rhamt_project_issues"></p>

<p>RHAMT provides helpful links to understand the issue deeper and offer guidance for the migration.</p>

<p>The WebLogic <code>ApplicationLifecycleListener</code> abstract class is used to perform functions or schedule jobs at Oracle WebLogic Server start and stop. In this case we have
code in the <code>postStart</code> and <code>preStop</code> methods which are executed after Weblogic starts up and before it shuts down, respectively.</p>

<p>In JBoss Enterprise Application Platform, there is no equivalent to 
intercept these events, but you can get equivalent functionality using a
 <em>Singleton EJB</em> with standard annotations,
as suggested in the issue in the RHAMT report.</p>

<p>We will use the <code>@Startup</code> annotation to tell the container to initialize the singleton session
bean at application start. We will similarly use the <code>@PostConstruct</code> and <code>@PreDestroy</code> annotations to specify the
methods to invoke at the start and end of the application lifecyle achieving the same result but without
using proprietary interfaces.</p>

<p>While the code in our startup and shutdown is very simple, in the 
real world this code may require additional thought as part of the 
migration. However,
using this method makes the code much more portable.</p>

<h4 id="fix-the-applicationlifecyclelistener-issues">3. Fix the ApplicationLifecycleListener issues</h4>

<hr>

<p>To begin we are fixing the issues under the Monolith application. 
Navigate to this folder in the project tree navigation pane to the left 
side, and edit the source files under there.</p>

<p>Open the file <code>src/main/java/com/redhat/coolstore/utils/StartupListener.java</code>. Navigate the folder tree and double-click the source file to open it in the editing panel.</p>

<p>The first issue we will tackle is the one reporting the use of <em>Weblogic ApplicationLifecyleEvent</em> and <em>Weblogic LifecycleListener</em> in this file. Open the file to make these changes in the file. Replace the file so it is as follows:</p>

<pre><code class="language-java">package com.redhat.coolstore.utils;

import javax.annotation.PostConstruct;
import javax.annotation.PreDestroy;
import javax.ejb.Startup;
import javax.inject.Singleton;
import javax.inject.Inject;
import java.util.logging.Logger;

@Singleton
@Startup
public class StartupListener {

    @Inject
    Logger log;

    @PostConstruct
    public void postStart() {
        log.info("AppListener(postStart)");
    }

    @PreDestroy
    public void preStop() {
        log.info("AppListener(preStop)");
    }

}
</code></pre>

<p><code>Tip</code>: Where is the SAVE button?  CodeReady workspaces 
will autosave your changes, that is why you can’t find a SAVE button - 
no more losing code because you forgot to save. You can undo with <code>CTRL+Z</code> (<code>CMD-Z</code> on Mac) or by using the <code>Edit -&gt; Undo</code> menu option.</p>

<h4 id="test-the-build">4. Test the build</h4>

<hr>

<p>Go to <code>Commands Palette</code> and dobule-click on <code>build</code> in CodeReady Workspaces:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/codeready-workspace-build.dms" alt="rhamt_project_issues"></p>

<p>If it builds successfully (you will see <code>BUILD SUCCESS</code>), then let’s move on to the next issue! If it does not compile,
verify you made all the changes correctly and try the build again.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/codeready-workspace-build-result.dms" alt="rhamt_project_issues"></p>

<p>In the next step, we will migrate some Weblogic-specific code in the app to use standard Java EE interfaces.</p>

<p>Some of our application makes use of Weblogic-specific logging methods, which offer features related to logging of
internationalized content, and client-server logging.</p>

<p>In this case we are using Weblogic’s <code>NonCatalogLogger</code> which is a simplified logging framework that doesn’t use
localized message catalogs (hence the term <em>NonCatalog</em>).</p>

<p>The WebLogic <code>NonCatalogLogger</code> is not supported on JBoss 
EAP (or any other Java EE platform), and should be migrated to a 
supported logging framework, such as the JDK Logger or JBoss Logging.</p>

<p>We will use the standard Java Logging framework, a much more portable framework. The framework also
<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/logging/overview.html#a1.17" target="_blank">supports internationalization</a> if needed.</p>

<h4 id="make-the-changes">5. Make the changes</h4>

<hr>

<p>Navigate to the <code>Monolith Folder</code> and work on the source files under here.</p>

<p>Open the <code>src/main/java/com/redhat/coolstore/service/OrderServiceMDB.java</code> file and replace its contents with:</p>

<pre><code class="language-java">package com.redhat.coolstore.service;

import javax.ejb.ActivationConfigProperty;
import javax.ejb.MessageDriven;
import javax.inject.Inject;
import javax.jms.JMSException;
import javax.jms.Message;
import javax.jms.MessageListener;
import javax.jms.TextMessage;

import com.redhat.coolstore.model.Order;
import com.redhat.coolstore.utils.Transformers;

import java.util.logging.Logger;

@MessageDriven(name = "OrderServiceMDB", activationConfig = {
	@ActivationConfigProperty(propertyName = "destinationLookup", propertyValue = "topic/orders"),
	@ActivationConfigProperty(propertyName = "destinationType", propertyValue = "javax.jms.Topic"),
	@ActivationConfigProperty(propertyName = "acknowledgeMode", propertyValue = "Auto-acknowledge")})
public class OrderServiceMDB implements MessageListener {

	@Inject
	OrderService orderService;

	@Inject
	CatalogService catalogService;

	private Logger log = Logger.getLogger(OrderServiceMDB.class.getName());

	@Override
	public void onMessage(Message rcvMessage) {
		TextMessage msg = null;
		try {
				if (rcvMessage instanceof TextMessage) {
						msg = (TextMessage) rcvMessage;
						String orderStr = msg.getBody(String.class);
						log.info("Received order: " + orderStr);
						Order order = Transformers.jsonToOrder(orderStr);
						log.info("Order object is " + order);
						orderService.save(order);
						order.getItemList().forEach(orderItem -&gt; {
							catalogService.updateInventoryItems(orderItem.getProductId(), orderItem.getQuantity());
						});
				}
		} catch (JMSException e) {
			throw new RuntimeException(e);
		}
	}

}
</code></pre>

<p>That one was pretty easy.</p>

<h4 id="test-the-build-1">6. Test the build</h4>

<hr>

<p>Build and package the app using Maven to make sure you code still compiles via CodeReady Workspaces <code>BUILD</code> window:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/codeready-workspace-build.dms" alt="rhamt_project_issues"></p>

<p>If builds successfully (you will see <code>BUILD SUCCESS</code>), then let’s move on to the next issue! If it does not compile,
verify you made all the changes correctly and try the build again.</p>

<p>In this final step we will again migrate some Weblogic-specific code in the app to use standard Java EE interfaces,
and one JBoss-specific interface.</p>

<p>Our application uses <a href="https://en.wikipedia.org/wiki/Java_Message_Service" target="_blank">JMS</a> to communicate. Each time an order is placed in the application, a JMS message is sent to
a JMS Topic, which is then consumed by listeners (subscribers) to that topic to process the order using <a href="https://docs.oracle.com/javaee/6/tutorial/doc/gipko.html" target="_blank">Message-driven beans</a>, a form
of Enterprise JavaBeans (EJBs) that allow Java EE applications to process messages asynchronously.</p>

<p>In this case, <code>InventoryNotificationMDB</code> is subscribed to and listening for messages from <code>ShoppingCartService</code>. When
an order comes through the <code>ShoppingCartService</code>, a message is placed on the JMS Topic. At that point, the <code>InventoryNotificationMDB</code>
receives a message and if the inventory service is below a pre-defined threshold, sends a message to the log indicating that
the supplier of the product needs to be notified.</p>

<p>Unfortunately this MDB was written a while ago and makes use of weblogic-proprietary interfaces to configure and operate the
MDB. RHAMT has flagged this and reported it using a number of issues.</p>

<p>JBoss EAP provides an even more efficient and declarative way
to configure and manage the lifecycle of MDBs. In this case, we can use annotations to provide the necessary initialization
and configuration logic and settings. We will use the
<code>@MessageDriven</code> and <code>@ActivationConfigProperty</code> annotations, along with the <code>MessageListener</code> interfaces to provide the
same functionality as from Weblogic.</p>

<p>Much of Weblogic’s interfaces for EJB components like MDBs reside in Weblogic descriptor XML files. Open
<code>src/main/webapp/WEB-INF/weblogic-ejb-jar.xml</code> to see one of these descriptors. There are many different configuration
possibilities for EJBs and MDBs in this file, but luckily our application only uses one of them, namely it configures
<code>&lt;trans-timeout-seconds&gt;</code> to 30, which means that if a given transaction within an MDB operation takes too
long to complete (over 30 seconds), then the transaction is rolled back and exceptions are thrown. This interface is
Weblogic-specific so we’ll need to find an equivalent in JBoss.</p>

<blockquote>
  <p>You should be aware that this type of migration is more involved than the previous steps, and in real world applications
it will rarely be as simple as changing one line at a time for a migration. Consult the <a href="https://access.redhat.com/documentation/en/red-hat-application-migration-toolkit" target="_blank">RHAMT documentation</a> for more detail on Red Hat’s
Application Migration strategies or contact your local Red Hat representative to learn more about how Red Hat can help you
on your migration path.</p>
</blockquote>

<h4 id="review-the-issues">7. Review the issues</h4>

<hr>

<p>From the RHAMT Issues report, we will fix the remaining issues:</p>

<ul>
  <li><code>Call of JNDI lookup</code> - Our apps use a weblogic-specific <a href="https://en.wikipedia.org/wiki/Java_Naming_and_Directory_Interface" target="_blank">JNDI</a> lookup scheme.</li>
  <li><code>Proprietary InitialContext initialization</code> - Weblogic has a very different lookup mechanism for InitialContext objects</li>
  <li><code>WebLogic InitialContextFactory</code> - This is related to the above, essentially a Weblogic proprietary mechanism</li>
  <li><code>WebLogic T3 JNDI binding</code> - The way EJBs communicate in Weblogic is over T2, a proprietary implementation of Weblogic.</li>
</ul>

<p>All of the above interfaces have equivalents in JBoss, however they 
are greatly simplified and overkill for our application which uses
JBoss EAP’s internal message queue implementation provided by <a href="https://activemq.apache.org/artemis/" target="_blank">Apache ActiveMQ Artemis</a>.</p>

<h4 id="remove-the-weblogic-ejb-descriptors">8. Remove the weblogic EJB Descriptors</h4>

<hr>

<p>The first step is to remove the unneeded <code>weblogic-ejb-jar.xml</code> file. This file is proprietary to Weblogic and not recognized or processed by JBoss
EAP. Delete the file on Eclipse Navigator:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/codeready-workspace-delete-jar.dms" alt="codeready-workspace-convert" width="500px"></p>

<p>While we’re at it, let’s remove the <code>stub weblogic implementation classes</code> added as part of the scenario.</p>

<p>Right-click on the <code>weblogic</code> folder and select <strong>Delete</strong> to delete the folder:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/codeready-workspace-delete-weblogic.dms" alt="codeready-workspace-convert" width="500px"></p>

<h4 id="fix-the-code">9. Fix the code</h4>

<hr>

<p>Open the <code>src/main/java/com/redhat/coolstore/service/InventoryNotificationMDB.java</code> file and replace its contents with:</p>

<pre><code class="language-java">package com.redhat.coolstore.service;

import com.redhat.coolstore.model.Order;
import com.redhat.coolstore.utils.Transformers;

import javax.ejb.ActivationConfigProperty;
import javax.ejb.MessageDriven;
import javax.inject.Inject;
import javax.jms.JMSException;
import javax.jms.Message;
import javax.jms.MessageListener;
import javax.jms.TextMessage;
import java.util.logging.Logger;

@MessageDriven(name = "InventoryNotificationMDB", activationConfig = {
        @ActivationConfigProperty(propertyName = "destinationLookup", propertyValue = "topic/orders"),
        @ActivationConfigProperty(propertyName = "destinationType", propertyValue = "javax.jms.Topic"),
        @ActivationConfigProperty(propertyName = "transactionTimeout", propertyValue = "30"),
        @ActivationConfigProperty(propertyName = "acknowledgeMode", propertyValue = "Auto-acknowledge")})
public class InventoryNotificationMDB implements MessageListener {

    private static final int LOW_THRESHOLD = 50;

    @Inject
    private CatalogService catalogService;

    @Inject
    private Logger log;

    public void onMessage(Message rcvMessage) {
        TextMessage msg;
        {
            try {
                if (rcvMessage instanceof TextMessage) {
                    msg = (TextMessage) rcvMessage;
                    String orderStr = msg.getBody(String.class);
                    Order order = Transformers.jsonToOrder(orderStr);
                    order.getItemList().forEach(orderItem -&gt; {
                        int old_quantity = catalogService.getCatalogItemById(orderItem.getProductId()).getInventory().getQuantity();
                        int new_quantity = old_quantity - orderItem.getQuantity();
                        if (new_quantity &lt; LOW_THRESHOLD) {
                            log.warning("Inventory for item " + orderItem.getProductId() + " is below threshold (" + LOW_THRESHOLD + "), contact supplier!");
                        }
                    });
                }


            } catch (JMSException jmse) {
                System.err.println("An exception occurred: " + jmse.getMessage());
            }
        }
    }
}
</code></pre>

<p>Remember the <code>&lt;trans-timeout-seconds&gt;</code> setting from the <code>weblogic-ejb-jar.xml</code> file? This is now set as an
<code>@ActivationConfigProperty</code> in the new code. There are pros and cons to using annotations vs. XML descriptors and care should be
taken to consider the needs of the application.</p>

<p>Your MDB should now be properly migrated to JBoss EAP.</p>

<h4 id="test-the-build-2">10. Test the build</h4>

<hr>

<p>Build and package the app using Maven to make sure you code still compiles via CodeReady Workspaces <code>BUILD</code> window:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/codeready-workspace-build.dms" alt="rhamt_project_issues"></p>

<p>If builds successfully (you will see <code>BUILD SUCCESS</code>), then let’s move on to the next issue! If it does not compile,
verify you made all the changes correctly and try the build again.</p>

<h4 id="re-run-the-rhamt-report">11. Re-run the RHAMT report</h4>

<hr>

<p>In this step we will re-run the RHAMT report to verify our migration was successful.</p>

<p>In the <a href="http://rhamt-web-console-labs-infra.apps.cluster-tokyo-069d.tokyo-069d.open.redhat.com/" target="_blank">RHAMT Console</a>, navigate to <code>Applications</code> on the left menu and click on <code>Add</code>. Enter the path to the fixed project at <code>/opt/solution</code> and click <strong>Upload</strong> to add the project:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/rhamt_rerun_analysis_report_solution.dms" alt="rhamt_rerun_analysis_report"></p>

<p>Be sure to delete the old <code>monolith.war</code> to avoid analyzing it again:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/rhamt_rerun_analysis_report_solution_del.dms" alt="rhamt_rerun_analysis_report"></p>

<p>and then click <strong>Save and Run</strong> to analyze the project:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/rhamt_rerun_analysis_report.dms" alt="rhamt_rerun_analysis_report"></p>

<p>Depending on how many other students are running reports, your analysis might be <em>queued</em> for several minutes. If it is taking too long, feel free to skip the next section and proceed to step <strong>13</strong> and return back to the analysis later to confirm that you eliminated all the issues.</p>

<h4 id="view-the-results">12. View the results</h4>

<hr>

<p>Click on the lastet result to go to the report web page and verify that it now reports 0 Story Points:</p>

<p>You have successfully migrated
this app to JBoss EAP, congratulations!</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/rhamt_project_issues_story.dms" alt="rhamt_project_issues_story"></p>

<p>Now that we’ve migrated the app, let’s deploy it and test it out and start to explore some of the features that JBoss EAP
plus Red Hat OpenShift bring to the table.</p>

<h4 id="add-an-openshift-profile">13. Add an OpenShift profile</h4>

<hr>

<p>Open the <code>pom.xml</code> file in <code>monolith</code> project.</p>

<p>At the <code>&lt;!-- TODO: Add OpenShift profile here --&gt;</code> we are going to add a the following configuration to the pom.xml</p>

<pre><code class="language-xml">        &lt;profile&gt;
          &lt;id&gt;openshift&lt;/id&gt;
          &lt;build&gt;
              &lt;plugins&gt;
                  &lt;plugin&gt;
                      &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt;
                      &lt;version&gt;2.6&lt;/version&gt;
                      &lt;configuration&gt;
                          &lt;webResources&gt;
                              &lt;resource&gt;
                                  &lt;directory&gt;${basedir}/src/main/webapp/WEB-INF&lt;/directory&gt;
                                  &lt;filtering&gt;true&lt;/filtering&gt;
                                  &lt;targetPath&gt;WEB-INF&lt;/targetPath&gt;
                              &lt;/resource&gt;
                          &lt;/webResources&gt;
                          &lt;outputDirectory&gt;deployments&lt;/outputDirectory&gt;
                          &lt;warName&gt;ROOT&lt;/warName&gt;
                      &lt;/configuration&gt;
                  &lt;/plugin&gt;
              &lt;/plugins&gt;
          &lt;/build&gt;
        &lt;/profile&gt;
</code></pre>

<h4 id="create-the-openshift-project">14. Create the OpenShift project</h4>

<hr>

<p>First, open a new brower with the ARO web console</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/openshift_login.dms" alt="openshift_login"></p>

<p>Login using:</p>

<ul>
  <li>Username: <code>userXX</code></li>
</ul>

<blockquote>
  <p><strong>NOTE</strong>: Use of self-signed certificates</p>

  <p>When you access the OpenShift web 
console](https://console-openshift-console.apps.cluster-tokyo-069d.tokyo-069d.open.redhat.com)
 or other URLs via <em>HTTPS</em> protocol, you will see browser warnings
like <code>Your &gt; Connection is not secure</code> since this workshop uses self-signed certificates (which you should not do in production!).
For example, if you’re using <strong>Chrome</strong>, you will see the following screen.</p>

  <p>Click on <code>Advanced</code> then, you can access the HTTPS page when you click on <code>Proceed to...</code>!!!</p>

  <p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/browser_warning.dms" alt="warning"></p>

  <p>Other browsers have similar procedures to accept the security exception.</p>
</blockquote>

<p>You will see the OpenShift landing page:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/openshift_landing.dms" alt="openshift_landing"></p>

<blockquote>
  <p>The project displayed in the landing page depends on which labs you will run today. If you will develop <code>Service Mesh and Identity</code> then you will see pre-created projects as the above screeenshot.</p>
</blockquote>

<p>Click <code>Create Project</code>, fill in the fields, and click <code>Create</code>:</p>

<ul>
  <li>Name: <code>userXX-coolstore-dev</code></li>
  <li>Display Name: <code>USERXX Coolstore Monolith - Dev</code></li>
  <li>Description: <em>leave this field empty</em></li>
</ul>

<blockquote>
  <p>NOTE: YOU <code>MUST</code> USE <code>userXX-coolstore-dev</code> AS THE PROJECT NAME, as this name is referenced later on and you will experience failures if you do not name it <code>userXX-coolstore-dev</code>!</p>
</blockquote>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/create_dialog.dms" alt="create_dialog" width="700px"></p>

<p>This will take you to the project status. There’s nothing there yet, but that’s about to change.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/create_new.dms" alt="create_new"></p>

<h4 id="deploy-the-monolith">15. Deploy the monolith</h4>

<hr>

<p>Although your Eclipse Che workspace is running on the Kubernetes cluster, it’s running with a default restricted <em>Service Account</em>
 that prevents you from creating most resource types. If you’ve 
completed other modules, you’re probably already logged in, but let’s 
login again: open a Terminal and issue the following command:</p>

<p><code>oc login https://$ADDRESS_OF_ARO --token=$YOURTOKEN</code></p>

<p>Enter your username and password assigned to you:</p>

<ul>
  <li>Username: <code>userXX</code></li>
</ul>

<p>You should see like:</p>

<pre><code class="language-shell">Login successful.</code></pre>


<p>Switch to the developer project you created earlier via CodeReady Workspaces Terminal window:</p>

<p><code>oc new-project userXX-coolstore-dev</code></p>

<p>And finally deploy template:</p>

<p><code>oc new-app oc new-app https://raw.githubusercontent.com/h-kojima/aro-handson/master/coolstore-monolith-binary-build.yml</code></p>

<p>This will deploy both a PostgreSQL database and JBoss EAP, but it will not start a build for our application.</p>

<p>Then open up the <code>userXX-coolstore-dev</code> project status page at ARO web console</p>

<p>and verify the monolith template items are created:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/no_deployments.dms" alt="no_deployments"></p>

<p>You can see the components being deployed on the
Project Status, but notice the <code>No running pod for Coolstore</code>. When you click on <code>coolstore DC</code>(Deployment Configs), you will see overview and resources.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/dc_overview.dms" alt="no_deployments"></p>

<p>You have not yet deployed the container image built in previous steps, but you’ll do that next.</p>

<h4 id="deploy-application-using-binary-build">16. Deploy application using Binary build</h4>

<hr>

<p>In this development project we have selected to use a process called <em>binary builds</em>, which
means that instead of pointing to a public Git Repository and have the S2I (Source-to-Image) build process
download, build, and then create a container image for us we are going to build locally
and just upload the artifact (e.g. the <code>.war</code> file). The binary deployment will speed up
the build process significantly.</p>

<p>First, build the project once more using the <code>openshift</code> Maven profile, which will create a
suitable binary for use with OpenShift (this is not a container image yet, but just the <code>.war</code>
file). We will do this with the <code>oc</code> command line.</p>

<p>Build the project via CodeReady Workspaces Terminal window:</p>

<p><code>cd /projects/cloud-native-workshop-v2m1-labs/monolith/</code></p>

<p><code>mvn clean package -Popenshift</code></p>

<blockquote>
  <p><code>NOTE</code>: Make sure to run this mvn command at working directory(i.e monolith).</p>
</blockquote>

<p>Wait for the build to finish and the <code>BUILD SUCCESS</code> message!</p>

<p>And finally, start the build process that will take the <code>.war</code> file and combine it with JBoss
EAP and produce a Linux container image which will be automatically deployed into the project,
thanks to the <em>DeploymentConfig</em> object created from the template:</p>

<p><code>oc start-build coolstore --from-file=deployments/ROOT.war </code></p>

<p>When you navigate <code>Builds</code> menu, you will find out <code>coolstore-xx</code> is <code>running</code> in Status field:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/building.dms" alt="building"></p>

<p>Wait for the build and deploy to complete:</p>

<p><code>oc rollout status -w dc/coolstore</code></p>

<p>This command will be used often to wait for deployments to complete. Be sure it returns success when you use it!
You should eventually see <code>replication controller "coolstore-1" successfully rolled out</code>.</p>

<blockquote>
  <p>If the above command reports <code>Error from server (ServerTimeout)</code> then simply re-run the command until it reports success!</p>
</blockquote>

<p>When it’s done you should see the application deployed successfully.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/build_done.dms" alt="build_done"></p>

<p>Test the application by clicking on the Route link at <code>Networking &gt; Routes</code> on the left menu:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/route_link.dms" alt="route_link"></p>

<h5 id="congratulations">Congratulations!</h5>

<p>Now you are using the same application that we built locally on OpenShift. That wasn’t too hard right?</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/coolstore_web.dms" alt="coolstore_web"></p>

<p>In the next step you’ll explore more of the developer features of OpenShift in preparation for moving the
monolith to a microservices architecture later on. Let’s go!</p>

<h4 id="summary">Summary</h4>

<hr>

<p>Now that you have migrating an existing Java EE app to the cloud
with JBoss and OpenShift, you are ready to start modernizing the
application by breaking the monolith into smaller microservices in
incremental steps, and employing modern techniques to ensure the
application runs well in a distributed and containerized environment.</p>

        <hr>
        <h2>Break Monolith Apart - I</h2>
        <h2 id="lab3---breaking-the-monolith-apart---i">Lab3 - Breaking the monolith apart - I</h2>

<p>In the previous labs you learned how to take an existing monolithic Java EE application to the cloud
with JBoss EAP and OpenShift, and you got a glimpse into the power of OpenShift for existing applications.</p>

<p>You will now begin the process of modernizing the application by breaking the application into multiple
microservices using different technologies, with the eventual goal of re-architecting the entire application as a set of
distributed microservices. Later on we’ll explore how you can better manage and monitor the application after
it is re-architected.</p>

<p>In this lab you will learn more about <code>Supersonic Subatomic Java</code> <a href="https://quarkus.io/" target="_blank">Quarkus</a>, which is designed to be container and developer friendly.</p>

<p>Quarkus is a <em>Kubernetes Native</em> Java stack, crafted from the 
best of breed Java libraries and standards.
Amazingly fast boot time, incredibly low RSS memory (not just heap 
size!) offering near instant scale up and high density memory 
utilization
in container orchestration platforms like Kubernetes. Quarkus uses a 
technique called compile time boot. <a href="https://quarkus.io/vision/container-first" target="_blank">Learn more</a>.</p>

<p>This will be one of the runtimes included in <a href="https://www.redhat.com/en/products/runtimes" target="_blank">Red Hat Runtimes</a>.</p>

<h4 id="goals-of-this-lab">Goals of this lab</h4>

<hr>

<p>You will implement one component of the monolith as a Quarkus microservice and modify it to address
microservice concerns, understand its structure, deploy it to OpenShift and exercise the interfaces between
Quarkus apps, microservices, and OpenShift/Kubernetes.</p>

<p>The goal is to deploy this new microservice alongside the existing monolith, and then later on we’ll tie them together.
But after this lab, you should end up with something like:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/goal.dms" alt="lab3_goal" width="700px"></p>

<h4 id="what-is-quarkus">What is Quarkus?</h4>

<hr>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/quarkus-logo.dms" alt="quarkus-logo"></p>

<p>For years, the client-server architecture has been the de-facto 
standard to build applications.
But a major shift happened. The one model rules them all age is over. A 
new range of applications
and architecture styles has emerged and impacts how code is written and 
how applications are deployed and executed.
HTTP microservices, reactive applications, message-driven microservices 
and serverless are now central players in modern systems.</p>

<p><a href="https://quarkus.io/" target="_blank">Quarkus</a> offers 4 major benefits to build cloud-native, microservices, and serverless Java applicaitons:</p>

<ul>
  <li>
    <p><strong>Developer Joy</strong> - Cohesive platform for optimized 
developer joy through unified configuration, Zero config with live 
reload in the blink of an eye,
 streamlined code for the 80% common usages with flexible for the 20%, 
and no hassle native executable generation.</p>
  </li>
  <li>
    <p><strong>Unifies Imperative and Reactive</strong> - Inject the EventBus or the Vertx context for both Reactive and imperative development in the same application.</p>
  </li>
  <li>
    <p><strong>Functions as a Service and Serverless</strong> - Superfast startup and low memory utilization. With Quarkus, you can embrace this new world without having
to change your programming language.</p>
  </li>
  <li>
    <p><strong>Best of Breed Frameworks &amp; Standards</strong> - 
CodeReady Workspaces Vert.x, Hibernate, RESTEasy, Apache Camel, 
CodeReady Workspaces MicroProfile, Netty, Kubernetes, OpenShift, Jaeger,
 Prometheus, Apacke Kafka, Infinispan, and more.</p>
  </li>
</ul>

<h4 id="setup-an-inventory-proejct">1. Setup an Inventory proejct</h4>

<hr>

<p>In the project explorer, expand the <strong>inventory</strong>  project.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/codeready-workspace-inventory-project.dms" alt="inventory_setup" width="500px"></p>

<h4 id="examine-the-maven-project-structure">2. Examine the Maven project structure</h4>

<hr>

<p>The sample Quarkus project shows a minimal CRUD service exposing a couple of endpoints over REST,
with a front-end based on Angular so you can play with it from your browser.</p>

<p>While the code is surprisingly simple, under the hood this is using:</p>

<ul>
  <li>RESTEasy to expose the REST endpoints</li>
  <li>Hibernate ORM with Panache to perform CRUD operations on the database</li>
  <li>A PostgreSQL database; see below to run one via Linux Container</li>
  <li>Some example <code>Dockerfile</code>s to generate new images for JVM and Native mode compilation</li>
</ul>

<p><code>Hibernate ORM</code> is the de facto JPA implementation and offers you the full breadth of an Object Relational Mapper.
It makes complex mappings possible, but it does not make simple and common mappings trivial. Hibernate ORM with
Panache focuses on making your entities trivial and fun to write in Quarkus.</p>

<p>Now let’s write some code and create a domain model, service interface and a RESTful endpoint to access inventory:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/inventory-arch.dms" alt="Inventory RESTful Service" width="700px"></p>

<h4 id="add-quarkus-extensions">3. Add Quarkus Extensions</h4>

<hr>

<p>We will add Quarkus extensions to the Inventory application for using <code>Panache</code> (a simplified way to access data via Hibernate ORM), a database with <code>Postgres</code> (in production) and <code>H2</code> (for testing) and we’ll use the Quarkus Maven Plugin. Copy the following commands to add the <em>Hibernate ORM with Panache</em> extension via CodeReady Workspaces Terminal:</p>

<p>Go to `inventory’ directory:</p>

<p><code>cd /projects/cloud-native-workshop-v2m1-labs/inventory/</code></p>

<p><code>mvn quarkus:add-extension -Dextensions="hibernate-orm-panache"</code></p>

<p>And then for local H2 database:</p>

<p><code>mvn quarkus:add-extension -Dextensions="jdbc-h2"</code></p>

<blockquote>
  <p>NOTE: There are many <a href="https://quarkus.io/extensions/" target="_blank">more extensions</a> for Quarkus for popular frameworks like <a href="https://vertx.io/" target="_blank">Vert.x</a>, <a href="http://camel.apache.org/" target="_blank">Apache Camel</a>, <a href="http://infinispan.org/" target="_blank">Infinispan</a>, Spring DI compatibility (e.g. <code>@Autowired</code>), and more.</p>
</blockquote>

<h4 id="create-inventory-entity">4. Create Inventory Entity</h4>

<hr>

<p>With our skeleton project in place, let’s get to work defining the business logic.</p>

<p>The first step is to define the model (entity) of an Inventory 
object. Since Quarkus uses Hibernate ORM Panache, we can re-use the same
 model definition from our monolithic application - no need to re-write 
or re-architect!</p>

<p>Open up the empty <strong>Inventory.java</strong> file in <em>com.redhat.coolstore</em> package and paste the following code into it (identical to the monolith code):</p>

<pre><code class="language-java">package com.redhat.coolstore;

import javax.persistence.Cacheable;
import javax.persistence.Entity;

import io.quarkus.hibernate.orm.panache.PanacheEntity;

@Entity
@Cacheable
public class Inventory extends PanacheEntity {

    public String itemId;
    public String location;
    public int quantity;
    public String link;

    public Inventory() {

    }

}
</code></pre>

<p>By extending <code>PanacheEntity</code> in your entities, you will get an ID field that is auto-generated. If you require a custom ID strategy, you can extend <code>PanacheEntityBase</code> instead and handle the ID yourself.</p>

<p>By using public fields, there is no need for functionless getters and
 setters (those that simply get or set the field). You simply refer to 
fields like <code>Inventory.location</code> without the need to write a <code>Inventory.getLocation()</code>
 implementation. Panache will auto-generate any getters and setters you 
do not write, or you can develop your own getters/setters that do more 
than get/set, which will be called when the field is accessed directly.</p>

<p>The <code>PanacheEntity</code> superclass comes with lots of super 
useful static methods and you can add your own in your derived entity 
class. Much like traditional object-oriented programming it’s natural 
and recommended to place custom queries as close to the entity as 
possible, ideally within the entity definition itself.
Users can just start using your entity Inventory by typing Inventory, 
and get completion for all the operations in a single place.</p>

<p>When an entity is annotated with <code>@Cacheable</code>, all its field values are cached except for collections and relations to other entities.
This means the entity can be loaded quicker without querying the database for frequently-accessed, but rarely-changing data.</p>

<h4 id="define-the-restful-endpoint-of-inventory">5. Define the RESTful endpoint of Inventory</h4>

<hr>

<p>In this step we will mirror the abstraction of a <em>service</em> so that we can inject the Inventory <em>service</em>
 into various places (like a RESTful resource endpoint) in the future. 
This is the same approach that our monolith uses, so we can re-use this 
idea again. Open up the empty <strong>InventoryResource.java</strong> class in the <em>com.redhat.coolstore</em> package.</p>

<p>Add this code to it:</p>

<pre><code class="language-java">package com.redhat.coolstore;

import java.util.List;
import java.util.stream.Collectors;

import javax.enterprise.context.ApplicationScoped;
import javax.json.Json;
import javax.ws.rs.Consumes;
import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.WebApplicationException;
import javax.ws.rs.core.Response;
import javax.ws.rs.ext.ExceptionMapper;
import javax.ws.rs.ext.Provider;

import org.jboss.resteasy.annotations.jaxrs.PathParam;

@Path("/services/inventory")
@ApplicationScoped
@Produces("application/json")
@Consumes("application/json")
public class InventoryResource {

    @GET
    public List&lt;Inventory&gt; getAll() {
        return Inventory.listAll();
    }

    @GET
    @Path("{itemId}")
    public List&lt;Inventory&gt; getAvailability(@PathParam String itemId) {
        return Inventory.&lt;Inventory&gt;streamAll()
        .filter(p -&gt; p.itemId.equals(itemId))
        .collect(Collectors.toList());
    }

    @Provider
    public static class ErrorMapper implements ExceptionMapper&lt;Exception&gt; {

        @Override
        public Response toResponse(Exception exception) {
            int code = 500;
            if (exception instanceof WebApplicationException) {
                code = ((WebApplicationException) exception).getResponse().getStatus();
            }
            return Response.status(code)
                    .entity(Json.createObjectBuilder().add("error", exception.getMessage()).add("code", code).build())
                    .build();
        }

    }
}
</code></pre>

<p>The above REST services defines two endpoints:</p>

<ul>
  <li>
    <p><code>/inventory</code> that is accessible via <em>HTTP GET</em> which will return all known product Inventory entities as JSON</p>
  </li>
  <li>
    <p><code>/inventory/&lt;itemId&gt;</code> that is accessible via <em>HTTP GET</em> at for example <code>/inventory/329199</code> with the last path parameter being the ID for which we want inventory status.</p>
  </li>
</ul>

<h4 id="add-inventory-data">6. Add inventory data</h4>

<hr>

<p>Let’s add inventory data to the database so we can test things out. Open up the <code>src/main/resources/import.sql</code> file and
copy the following SQL statements to <strong>import.sql</strong>:</p>

<pre><code class="language-sql">INSERT INTO INVENTORY (id, itemId, link, location, quantity) values (nextval('hibernate_sequence'), '329299', 'http://maps.google.com/?q=Raleigh', 'Raleigh', 736);
INSERT INTO INVENTORY (id, itemId, link, location, quantity) values (nextval('hibernate_sequence'), '329199', 'http://maps.google.com/?q=Boston', 'Boston', 512);
INSERT INTO INVENTORY (id, itemId, link, location, quantity) values (nextval('hibernate_sequence'), '165613', 'http://maps.google.com/?q=Seoul', 'Seoul', 256);
INSERT INTO INVENTORY (id, itemId, link, location, quantity) values (nextval('hibernate_sequence'), '165614', 'http://maps.google.com/?q=Singapore', 'Singapore', 54);
INSERT INTO INVENTORY (id, itemId, link, location, quantity) values (nextval('hibernate_sequence'), '165954', 'http://maps.google.com/?q=London', 'London', 87);
INSERT INTO INVENTORY (id, itemId, link, location, quantity) values (nextval('hibernate_sequence'), '444434', 'http://maps.google.com/?q=NewYork', 'NewYork', 443);
INSERT INTO INVENTORY (id, itemId, link, location, quantity) values (nextval('hibernate_sequence'), '444435', 'http://maps.google.com/?q=Paris', 'Paris', 600);
INSERT INTO INVENTORY (id, itemId, link, location, quantity) values (nextval('hibernate_sequence'), '444437', 'http://maps.google.com/?q=Tokyo', 'Tokyo', 230);
</code></pre>

<p>In Development, we will configure to use local in-memory H2 database for local testing. Add these lines to <code>src/main/resources/application.properties</code>:</p>

<pre><code>quarkus.datasource.url=jdbc:h2:file://projects/database.db
quarkus.datasource.driver=org.h2.Driver
quarkus.datasource.username=inventory
quarkus.datasource.password=mysecretpassword
quarkus.datasource.max-size=8
quarkus.datasource.min-size=2
quarkus.hibernate-orm.database.generation=drop-and-create
quarkus.hibernate-orm.log.sql=false
</code></pre>

<h4 id="run-quarkus-inventory-application">7. Run Quarkus Inventory application</h4>

<hr>

<p>Now we are ready to run the inventory application. Click on <strong>Commands Palette</strong> then select <strong>Build and Run Locally</strong> in Run menu:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/quarkus-dev-run-paletter.dms" alt="codeready-workspace-maven"></p>

<blockquote>
  <p>This simply runs <code>mvn compile quarkus:dev</code> for you</p>
</blockquote>

<p>You should see a bunch of log output that ends with:</p>

<pre><code>2019-09-26 15:55:38,447 INFO  [io.quarkus] (main) Quarkus 0.22.0 started in 2.905s. Listening on: http://0.0.0.0:8080
2019-09-26 15:55:38,447 INFO  [io.quarkus] (main) Profile dev activated. Live Coding activated.
2019-09-26 15:55:38,447 INFO  [io.quarkus] (main) Installed features: [agroal, cdi, hibernate-orm, jdbc-h2, narayana-jta, resteasy, resteasy-jsonb]
</code></pre>

<p>Open a <strong>new</strong> CodeReady Workspaces Terminal and invoke the RESTful endpoint using the following CURL commands. The output looks like here:</p>

<p><code>curl http://localhost:8080/services/inventory ; echo</code></p>

<pre><code class="language-json">[{"id":1,"itemId":"329299","link":"http://maps.google.com/?q=Raleigh","location":"Raleigh","quantity":736},{"id":2,"itemId":"329199","link":"http://maps.google.com
/?q=Boston","location":"Boston","quantity":512},{"id":3,"itemId":"165613","link":"http://maps.google.com/?q=Seoul","location":"Seoul","quantity":256},{"id":4,"item
Id":"165614","link":"http://maps.google.com/?q=Singapore","location":"Singapore","quantity":54},{"id":5,"itemId":"165954","link":"http://maps.google.com/?q=London"
,"location":"London","quantity":87},{"id":6,"itemId":"444434","link":"http://maps.google.com/?q=NewYork","location":"NewYork","quantity":443},{"id":7,"itemId":"444
435","link":"http://maps.google.com/?q=Paris","location":"Paris","quantity":600},{"id":8,"itemId":"444437","link":"http://maps.google.com/?q=Tokyo","location":"Tok
yo","quantity":230}]
</code></pre>

<p><code>curl http://localhost:8080/services/inventory/329199 ; echo</code></p>

<pre><code class="language-json">[{"id":2,"itemId":"329199","link":"http://maps.google.com/?q=Boston","location":"Boston","quantity":512}]
</code></pre>

<h5 id="stop-the-application">Stop the application</h5>

<p>Stop Quarkus development mode by closing the <em>Build and Run Locally</em> Terminal window.</p>

<h4 id="add-test-code-and-create-a-package">8. Add Test Code and create a package</h4>

<hr>

<p>In this step, we will add unit tests so that we can test during <code>mvn package</code>.
Open up the <code>src/test/java/com/redhat/coolstore/InventoryEndpointTest.java</code> file and replace the following code with the below code:</p>

<pre><code class="language-java">package com.redhat.coolstore;

import static io.restassured.RestAssured.given;
import static org.hamcrest.CoreMatchers.containsString;

import io.quarkus.test.junit.QuarkusTest;
import org.junit.jupiter.api.Test;

@QuarkusTest
public class InventoryEndpointTest {

    @Test
    public void testListAllInventory() {
        //List all, should have all 8 cities inventory the database has initially:
        given()
              .when().get("/services/inventory")
              .then()
              .statusCode(200)
              .body(
                    containsString("Raleigh"),
                    containsString("Boston"),
                    containsString("Seoul"),
                    containsString("Singapore"),
                    containsString("London"),
                    containsString("NewYork"),
                    containsString("Paris"),
                    containsString("Tokyo")
                    );

        //List a certain item(ID:329299), Raleigh should be returned:
        given()
        .when().get("/services/inventory/329299")
        .then()
        .statusCode(200)
        .body(
              containsString("Raleigh")
        );
    }

}
</code></pre>

<p>Next we’ll build an executable jar then deploy it to <strong>OpenShift</strong> soon. Use the following maven command via CodeReady Workspaces Terminal:</p>

<p><code>cd /projects/cloud-native-workshop-v2m1-labs/inventory</code></p>

<p><code>mvn clean package</code></p>

<p>If OutofMemory Error occures, then execute following the code.</p>

<p><code>MAVEN_OPTS="-Xmx1024M -Xss128M -XX:MetaspaceSize=512M -XX:MaxMetaspaceSize=1024M -XX:+CMSClassUnloadingEnabled" mvn clean package</code></p>

<p>If builds successfully (you will see <strong>BUILD SUCCESS</strong>), continue to the next step to deploy the application to OpenShift.</p>

<p>You can also run the Uber.jar to make sure if the inventory works. Use the following <strong>Java command</strong> then you see a similar output:</p>

<p><code>java -jar target/inventory-1.0-SNAPSHOT-runner.jar</code></p>

<pre><code>2019-09-26 16:16:08,977 INFO  [io.quarkus] (main) Quarkus 0.23.1 started in 1.806s. Listening on: http://0.0.0.0:8080
2019-09-26 16:16:08,989 INFO  [io.quarkus] (main) Profile prod activated.
2019-09-26 16:16:08,989 INFO  [io.quarkus] (main) Installed features: [agroal, cdi, hibernate-orm, jdbc-h2, narayana-jta, resteasy, resteasy-jsonb]
</code></pre>

<p>Open a new CodeReady Workspaces Terminal and invoke the RESTful 
endpoint using the following CURL commands. The output looks like here:</p>

<p><code>curl http://localhost:8080/services/inventory ; echo</code></p>

<pre><code class="language-json">[{"id":1,"itemId":"329299","link":"http://maps.google.com/?q=Raleigh","location":"Raleigh","quantity":736},{"id":2,"itemId":"329199","link":"http://maps.google.com
/?q=Boston","location":"Boston","quantity":512},{"id":3,"itemId":"165613","link":"http://maps.google.com/?q=Seoul","location":"Seoul","quantity":256},{"id":4,"item
Id":"165614","link":"http://maps.google.com/?q=Singapore","location":"Singapore","quantity":54},{"id":5,"itemId":"165954","link":"http://maps.google.com/?q=London"
,"location":"London","quantity":87},{"id":6,"itemId":"444434","link":"http://maps.google.com/?q=NewYork","location":"NewYork","quantity":443},{"id":7,"itemId":"444
435","link":"http://maps.google.com/?q=Paris","location":"Paris","quantity":600},{"id":8,"itemId":"444437","link":"http://maps.google.com/?q=Tokyo","location":"Tok
yo","quantity":230}]
</code></pre>

<p><code>curl http://localhost:8080/services/inventory/329199 ; echo</code></p>

<pre><code class="language-json">[{"id":2,"itemId":"329199","link":"http://maps.google.com/?q=Boston","location":"Boston","quantity":512}]
</code></pre>

<h5 id="stop-the-application-1">Stop the application</h5>

<p>Stop Quarkus development mode by closing the Terminal window in which you ran <code>java -jar</code></p>

<p>You have now successfully created your first microservice using Quarkus and implemented a basic RESTful
API on top of the Inventory database. Most of the code looks simpler than the monolith, demonstrating how
easy it is to migrate existing monolithic Java EE application to microservices using <code>Quarkus</code>.</p>

<p>In next steps of this lab we will deploy our application to OpenShift Container Platform and then start
adding additional features to take care of various aspects of cloud native microservice development.</p>

<h4 id="create-openshift-project">9. Create OpenShift Project</h4>

<hr>

<p>We have already deployed our coolstore monolith to OpenShift, but now we are working on re-architecting it to be
microservices-based.</p>

<p>In this step, we will deploy our new Inventory microservice for our CoolStore application,
so create a separate project to house it and keep it separate from our monolith and our other microservices we will
create later on.</p>

<p>Before going to OpenShift console, we will repackage the Quarkus application for adding a PostgreSQL extension
because our Inventory service will connect to PostgeSQL database in production on OpenShift.</p>

<p>Add a <em>quarkus-jdbc-postgresql</em> extension via CodeReady Workspaces Terminal:</p>

<p><code>cd /projects/cloud-native-workshop-v2m1-labs/inventory/</code></p>

<p><code>mvn quarkus:add-extension -Dextensions="jdbc-postgresql"</code></p>

<p>Quarkus supports the notion of <em>configuration profiles</em>. These allows you to have multiple configurations in the same file and select between
then via a <em>profile name</em>.</p>

<p>By default Quarkus has three profiles, although it is possible to use as many as you like. The default profiles are:</p>

<ul>
  <li>
    <p><strong>dev</strong> - Activated when in development mode (i.e. <strong>quarkus:dev</strong>)</p>
  </li>
  <li>
    <p><strong>test</strong> - Activated when running tests</p>
  </li>
  <li>
    <p><strong>prod</strong> - The default profile when not running in development or test mode</p>
  </li>
</ul>

<p>There are two ways to set a custom profile, either via the <code>quarkus.profile</code> system property or the <code>QUARKUS_PROFILE</code>
 environment variable.
If both are set the system property takes precedence. Note that it is 
not necessary to define the names of these profiles anywhere,
all that is necessary is to create a config property with the profile 
name, and then set the current profile to that name.</p>

<p>Let’s add the following variables in <em>src/main/resources/application.properties</em>:</p>

<pre><code class="language-shell">%prod.quarkus.datasource.url=jdbc:postgresql://inventory-database:5432/inventory
%prod.quarkus.datasource.driver=org.postgresql.Driver
%prod.quarkus.datasource.username=inventory
%prod.quarkus.datasource.password=mysecretpassword
%prod.quarkus.datasource.max-size=8
%prod.quarkus.datasource.min-size=2
%prod.quarkus.hibernate-orm.database.generation=drop-and-create
%prod.quarkus.hibernate-orm.sql-load-script=import.sql
%prod.quarkus.hibernate-orm.log.sql=true
</code></pre>

<p>Repackage the inventory application via clicking on <strong>Package for OpenShift</strong> in Commands Palette:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/quarkus-dev-run-packageforOcp.dms" alt="codeready-workspace-maven"></p>

<p>In OpenShift, click on the name of the <strong>userXX-inventory</strong> project:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/create_new_inventory.dms" alt="create_new"></p>

<p>This will take you to the project overview. There’s nothing there yet, but that’s about to change.</p>

<h4 id="deploy-to-openshift">10. Deploy to OpenShift</h4>

<hr>

<p>Let’s deploy our new inventory microservice to OpenShift!</p>

<p>Our production inventory microservice will use an external database (PostgreSQL) to house inventory data.
First, deploy a new instance of PostgreSQL by executing the following commands via CodeReady Workspaces Terminal:</p>

<p><code>oc new-project userXX-inventory</code></p>

<p>Then run:</p>

<pre><code class="language-shell">oc new-app -e POSTGRESQL_USER=inventory \
  -e POSTGRESQL_PASSWORD=mysecretpassword \
  -e POSTGRESQL_DATABASE=inventory openshift/postgresql:10 \
  --name=inventory-database
</code></pre>

<blockquote>
  <p>NOTE: If you change the username and password you also need to update <code>src/main/resources/application.properties</code> which contains
the credentials used when deploying to OpenShift.</p>
</blockquote>

<p>This will deploy the database to our new project.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/inventory-database-deployment.dms" alt="inventory_db_deployments"></p>

<h4 id="build-and-deploy">11. Build and Deploy</h4>

<hr>

<p>Red Hat OpenShift Application Runtimes includes a powerful maven plugin that can take an
existing Quarkus application and generate the necessary Kubernetes configuration.</p>

<p>Build and deploy the project using the following command, which will 
use the maven plugin to deploy via CodeReady Workspaces Terminal:</p>

<p><code>oc new-build 
registry.access.redhat.com/redhat-openjdk-18/openjdk18-openshift:1.5 
--binary --name=inventory-quarkus -l app=inventory-quarkus</code></p>

<p>This build uses the new <a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_middleware_for_openshift/3/html/red_hat_java_s2i_for_openshift/index" target="_blank">Red Hat OpenJDK Container Image</a>, providing foundational software needed to run Java applications, while staying at a reasonable size.</p>

<blockquote>
  <p>NOTE: After a while, you may get logged out of OpenShift. If the 
above command fails due to permissions, you can repeat the OpenShift 
login process from earlier.</p>
</blockquote>

<p>Start and watch the build, which will take about a minute to complete:</p>

<p><code>oc start-build inventory-quarkus --from-file target/*-runner.jar --follow</code></p>

<p>Once the build is done, we’ll deploy it as an OpenShift application 
and override the Postgres URL to specify our production Postgres 
credentials:</p>

<p><code>oc new-app inventory-quarkus -e QUARKUS_PROFILE=prod</code></p>

<p>and expose your service to the world:</p>

<p><code>oc expose service inventory-quarkus</code></p>

<p>Finally, make sure it’s actually done rolling out:</p>

<p><code>oc rollout status -w dc/inventory-quarkus</code></p>

<p>Wait for that command to report replication controller “inventory-quarkus-1” successfully rolled out before continuing.</p>

<blockquote>
  <p>NOTE: Even if the rollout command reports success the application 
may not be ready yet and the reason for that is that we currently don’t 
have any liveness/readiness check configured, but we will add that in 
the next steps.</p>
</blockquote>

<p>And now we can access using curl once again to find all inventories:</p>

<p><code>export URL="http://$(oc get route | grep inventory | awk '{print $2}')"</code></p>

<p><code>curl $URL/services/inventory ; echo</code></p>

<p>So now <code>Inventory</code> service is deployed to OpenShift. You can also see it in the Project Status in the OpenShift Console
with its single replica running in 1 pod, along with the Postgres database pod.</p>

<h4 id="access-the-application-running-on-openshift">12. Access the application running on OpenShift</h4>

<hr>

<p>This sample project includes a simple UI that allows you to access the Inventory API. This is the same
UI that you previously accessed outside of OpenShift which shows the CoolStore inventory. Click on the
route URL at <code>Networking &gt; Routes</code> to access the sample UI.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/inventory-route-link.dms" alt="Overview link"></p>

<blockquote>
  <p>NOTE: If you get a ‘404 Not Found’ error, just reload the page a 
few times until the Inventory UI appears. This is due to a lack of 
health check which you are about to fix!</p>
</blockquote>

<p>You can also access the application through the link on the <code>Project Status</code> page.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/inventory-route-link-status.dms" alt="Overview link"></p>

<p>The UI will refresh the inventory table every 2 seconds, as before.</p>

<p>In the next steps you will enhance OpenShift’s ability to manage the application lifecycle by implementing
a <em>health check pattern</em>. By default, without health checks (or health <em>probes</em>) OpenShift considers services
to be ready to accept service requests even before the application is truly ready or if the application is hung
or otherwise unable to service requests. OpenShift must be <em>taught</em> how to recognize that our app is alive and ready
to accept requests.</p>

<h5 id="what-is-microprofile-health">What is MicroProfile Health?</h5>

<p><strong>MicroProfile Health</strong> allows applications to provide 
information about their state to external viewers which is typically 
useful in cloud environments where automated processes must be able to 
determine whether the application should be discarded or restarted. <strong>Quarkus application</strong> can utilize the MicroProfile Health specification through the <em>SmallRye Health extension</em>.</p>

<h5 id="what-is-a-health-check">What is a Health Check?</h5>

<p>A key requirement in any managed application container environment is
 the ability to determine when the application is in a ready state. Only
 when an application has reported as ready can the manager (in this case
 OpenShift) act on the next step of the deployment process. OpenShift 
makes use of various <em>probes</em> to determine the health of an application during its lifespan. A <em>readiness</em>
 probe is one of these mechanisms for validating application health and 
determines when an application has reached a point where it can begin to
 accept incoming traffic. At that point, the IP address for the pod is 
added to the list of endpoints backing the service and it can begin to 
receive requests. Otherwise traffic destined for the application could 
reach the application before it was fully operational resulting in error
 from the client perspective.</p>

<p>Once an application is running, there are no guarantees that it will 
continue to operate with full functionality. Numerous factors including 
out of memory errors or a hanging process can cause the application to 
enter an invalid state. While a <em>readiness</em> probe is only 
responsible for determining whether an application is in a state where 
it should begin to receive incoming traffic, a <em>liveness</em> probe 
is used to determine whether an application is still in an acceptable 
state. If the liveness probe fails, OpenShift will destroy the pod and 
replace it with a new one.</p>

<p>In our case we will implement the health check logic in a REST endpoint and let Quarkus publish that logic on the <em>/health</em> endpoint for use with OpenShift.</p>

<h4 id="add-health-check-extension">13. Add Health Check Extension</h4>

<hr>

<p>We will add a Qurakus extension to the Inventory application for using <strong>smallrye-health</strong> and we’ll use the Quarkus Maven Plugin.
Copy the following commands to import the smallrye-health extension that implements the MicroProfile Health specification
via CodeReady Workspaces Terminal:</p>

<p>Go to <code>inventory</code> directory and add the extension:</p>

<p><code>cd /projects/cloud-native-workshop-v2m1-labs/inventory/</code></p>

<p><code>mvn quarkus:add-extension -Dextensions="health"</code></p>

<h4 id="run-the-health-check">14. Run the health check</h4>

<hr>

<p>When you import the <em>smallrye-health extension</em>, the <code>/health</code> endpoint is automatically exposed directly that can be used to run the health check procedures.</p>

<ul>
  <li>Run the Inventory application via <code>mvn compile quarkus:dev</code> or click on <strong>Build and Run Locally</strong> in Commands Palette:</li>
</ul>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/quarkus-dev-run-paletter.dms" alt="codeready-workspace-maven"></p>

<ul>
  <li>In a separate Terminal, access the <code>health check</code> endpoint using <code>curl http://localhost:8080/health</code> and the result should look like:</li>
</ul>

<pre><code class="language-json">{
      "status": "UP",
     "checks": [
     ]
}
</code></pre>

<p>The health REST endpoint returns a simple JSON object with two fields:</p>

<ul>
  <li><strong>status</strong> - the overall result of all the health check procedures</li>
  <li><strong>checks</strong> - an array of individual checks</li>
</ul>

<p>The general <em>status</em> of the health check is computed as a logical AND of all the declared health check procedures.
The <em>checks</em> array is empty as we have not specified any health check procedure yet so let’s define some.</p>

<h4 id="create-your-first-health-check">15. Create your first health check</h4>

<hr>

<p>Next, let’s fill in the class by creating a new RESTful endpoint which will be used by OpenShift to probe our services.
Open empty Java class: <strong>src/main/java/com/redhat/coolstore/InventoryHealthCheck.java</strong> and the following logic will be put into a new Java class.</p>

<p>Replace the following codes with the exsiting entire codes:</p>

<pre><code class="language-java">package com.redhat.coolstore;

import javax.enterprise.context.ApplicationScoped;
import javax.inject.Inject;

import org.eclipse.microprofile.health.HealthCheck;
import org.eclipse.microprofile.health.HealthCheckResponse;
import org.eclipse.microprofile.health.Readiness;

@Readiness
@ApplicationScoped
public class InventoryHealthCheck implements HealthCheck {

    @Inject
    private InventoryResource inventoryResource;

    @Override
    public HealthCheckResponse call() {

        if (inventoryResource.getAll() != null) {
            return HealthCheckResponse.named("Success of Inventory Health Check!!!").up().build();
        } else {
            return HealthCheckResponse.named("Failure of Inventory Health Check!!!").down().build();
        }
    }
}
</code></pre>

<p>The <strong>call()</strong> method exposes an HTTP GET endpoint which
 will return the status of the service. The logic of this check does a 
simple query to the underlying database to ensure the connection to it 
is stable and available. The method is also annotated with Quarkus’s <strong>@Readiness</strong> annotation, which directs Quarkus to expose this endpoint as a health check at <em>/health/ready</em>.</p>

<blockquote>
  <p>NOTE: You don’t need to stop and re-run re-run the Inventory application because Quarkus will <strong>reload the changes automatically</strong>.</p>
</blockquote>

<p>Access the <em>Readiness health check</em> endpoint again using <em>curl</em> and the result looks like:</p>

<p><code>curl http://localhost:8080/health/ready</code></p>

<pre><code class="language-json">{
   "status": "UP",
    "checks": [
        {
            "name": "Success of Inventory Health Check!!!",
            "state": "UP"
        }
    ]
}
</code></pre>

<p>With our new health check in place, we’ll need to build and deploy 
the updated application in the next step. Before move to the next step, 
be sure to close the termial where you’re running Quarkus development 
mode.</p>

<p><code>Tip</code>: You can define liveness probe using <strong>@Liveness</strong> annotation and the liveness check can be accessible at <strong>/health/live</strong> endpoint.</p>

<h4 id="re-deploy-to-openshift">16. Re-Deploy to OpenShift</h4>

<hr>

<p>Repackage the inventory application via clicking on <strong>Package for OpenShift</strong> in Commands Palette:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/quarkus-dev-run-packageforOcp.dms" alt="codeready-workspace-maven"></p>

<p>Start and watch the build, which will take about a minute to complete:</p>

<p><code>oc start-build inventory-quarkus --from-file target/*-runner.jar --follow</code></p>

<p>You should see a <strong>Push successful</strong> at the end of the build output and it. To verify that deployment is started and completed automatically,
run the following command via CodeReady Workspaces Terminal:</p>

<p><code>oc rollout status -w dc/inventory-quarkus</code></p>

<p>And wait for the result as below:</p>

<p><code>replication controller "inventory-quarkus-XX" successfully rolled out</code></p>

<p>Let’s set <em>readiness probe</em> in OpenShift using <em>InventoryHealthCheck</em>. Run the follwing <em>oc set probe</em> command in CodeReady Workspaces:</p>

<p><code>oc set probe dc/inventory-quarkus --readiness --get-url=http://:8080/health/ready</code></p>

<p>This will instruct OpenShift to use the <code>/health/ready</code> endpoint to continually check the health of the app.</p>

<p>Back on the OpenShift console, Navigate to <em>Deployment Configs</em> on the left menu then click on <em>inventory-quarkus</em>:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/inventory-dc.dms" alt="inventory-dc"></p>

<p>Click on <em>YAML</em> tab then you will see the following variables in <em>template.spec.containers.resources</em> path:</p>

<pre><code class="language-yaml">        readinessProbe:
            httpGet:
              path: /health/ready
              port: 8080
              scheme: HTTP
            timeoutSeconds: 1
            periodSeconds: 10
            successThreshold: 1
            failureThreshold: 3
</code></pre>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/inventory-healthcheck-webconsole.dms" alt="inventory-healthcheck-webconsole"></p>

<p>You should also be able to access the health check logic at the <em>inventory</em> endpoint via a web browser:</p>

<p><code>export URL="http://$(oc get route | grep inventory | awk '{print $2}')"</code></p>

<p><code>curl $URL/health/ready ; echo</code></p>

<p>You should see a JSON response like:</p>

<pre><code class="language-java">{
    "status": "UP",
    "checks": [
        {
            "name": "Success of Inventory Health Check!!!",
          "state": "UP"
        }
    ]
}
</code></pre>

<p>You can see the definition of the health check from the perspective of OpenShift via CodeReady Workspaces Terminal:</p>

<p><code>oc describe dc/inventory-quarkus | egrep 'Readiness|Liveness'</code></p>

<p>You should see:</p>

<blockquote>
  <pre><code>Readiness:  http-get http://:8080/health/ready delay=0s timeout=1s period=10s #success=1 #failure=3
</code></pre>
</blockquote>

<h4 id="adjust-probe-timeout">17. Adjust probe timeout</h4>

<hr>

<p>The various timeout values for the probes can be configured in many ways. Let’s tune the <em>readiness probe</em> initial delay so that we have to wait 3o seconds for it to be activated. Use the <em>oc</em> command to tune the probe to wait 30 seconds before starting to poll the probe:</p>

<p><code>oc set probe dc/inventory-quarkus --readiness --initial-delay-seconds=30</code></p>

<p>And verify it’s been changed (look at the <em>delay=</em> value for the Readiness probe) via CodeReady Workspaces Terminal:</p>

<p><code>oc describe dc/inventory-quarkus | egrep 'Readiness|Liveness'</code></p>

<blockquote>
  <pre><code>Readiness:  http-get http://:8080/health/ready delay=30s timeout=1s period=10s #success=1 #failure=3
</code></pre>
</blockquote>

<p>In the next step, we’ll exercise the probe and watch as it fails and OpenShift recovers the application.</p>

<h4 id="exercise-health-check">18. Exercise Health Check</h4>

<hr>

<p>From the project status page, click on the route link to open the sample application UI:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/inventory-route-link.dms" alt="Route Link"></p>

<p>This will open up the sample application UI in a new browser tab:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/app.dms" alt="App UI"></p>

<p>The app will begin polling the inventory as before and report success:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/inventory.dms" alt="Greeting"></p>

<p>Now you will corrupt the service and cause its health check to start 
failing.
To simulate the app crasing, let’s kill the underlying service so it 
stops responding. Execute via CodeReady Workspaces Terminal:</p>

<p><code>oc rsh dc/inventory-quarkus pkill java</code></p>

<p>This will execute the Linux <strong>pkill</strong> command to stop the running Java process in the container.</p>

<p>Check out the application sample UI page and notice it is now failing to access the inventory data, and the
<em>Last Successful Fetch</em> counter starts increasing, indicating that the UI cannot access inventory. This could have
been caused by an overloaded server, a bug in the code, or any other reason that could make the application
unhealthy.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/inventory-fail.dms" alt="Greeting"></p>

<p>At this point, return to the ARO web console and click on the <em>Pods</em> on the left menu. Notice that the
<strong>ContainersNotReady</strong> indicates the application is failing its <em>readiness probe</em>:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/notready.dms" alt="Not Ready"></p>

<p>After too many healthcheck probe failures, OpenShift will forcibly 
kill the pod and container running the service, and spin up a new one to
 take its place. Once this occurs, the light blue circle should return 
to dark blue. This should take about 30 seconds.</p>

<p>Return to the same sample app UI (without reloading the page) and 
notice that the UI has automatically re-connected to the new service and
 successfully accessed the inventory once again:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/inventory.dms" alt="Greeting"></p>

<h4 id="summary">Summary</h4>

<hr>

<p>You learned a bit more about what Quarkus is, and how it can be used to create modern Java microservice-oriented applications.</p>

<p>You created a new Inventory microservice representing functionality 
previously implmented in the monolithic CoolStore application. For now 
this new microservice is completely disconnected from our monolith and 
is not very useful on its own. In future steps you will link this and 
other microservices into the monolith to
begin the process of <a href="https://www.martinfowler.com/bliki/StranglerApplication.html" target="_blank">strangling the monolith</a>.</p>

<p>Quarkus brings in a number of concepts and APIs from the Java EE 
community, so your existing Java EE skills can be re-used to bring your 
applications into the modern world of containers, microservices and 
cloud deployments.</p>

<p>Quarkus will be one of many components of Red Hat OpenShift Application Runtimes soon. <strong>Stay tuned!!</strong>
In the next lab, you’ll use Spring Boot, another popular framework, to implement additional microservices. Let’s go!</p>

        <hr>
        <h2>Break Monolith Apart - II</h2>
        <h2 id="lab4---breaking-the-monolith-apart---ii">Lab4 - Breaking the monolith apart - II</h2>

<p>In the previous lab, you learned how to take an existing monolithic app and refactor a single <em>inventory</em> service using
Quarkus. The previous lab resulted in you creating an inventory service, but so far we haven’t started
<em>strangling</em> the monolith. That is because the inventory service is never called directly by the UI. It’s a backend service
that is only used only by other backend services. In this lab, you will create the catalog service and the catalog
service will call the inventory service. When you are ready, you will change the route to tie the UI calls to new service.</p>

<p>To implement this, we are going to use the Spring Framework. The reason for using Spring for this service is to introduce you
to Spring Development, and how <a href="https://www.redhat.com/en/products/runtimes" target="_blank">Red Hat Runtimes</a> helps to
make Spring development on Kubernetes easy. In real life, the reason for choosing Spring vs. others mostly depends on
personal preferences, like existing knowledge, etc. At the core Spring and Java EE are very similar.</p>

<p>The goal is to produce something like:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-goal.dms" alt="Greeting" width="700px"></p>

<h4 id="what-is-spring-framework">What is Spring Framework?</h4>

<hr>

<p>Spring is one of the most popular Java Frameworks and offers an alternative to the Java EE programming model. Spring
is also very popular for building applications based on microservices architectures. Spring Boot is a popular tool in
the Spring ecosystem that helps with organizing and using 3rd-party libraries together with Spring and also provides a
mechanism for boot strapping embeddable runtimes, like Apache Tomcat. Bootable applications (sometimes also called <em>fat jars</em>)
fits the container model very well since in a container platform like OpenShift responsibilities like starting, stopping and
monitoring applications are then handled by the container platform instead of an Application Server.</p>

<h4 id="aggregate-microservices-calls">Aggregate microservices calls</h4>

<hr>

<p>Another thing you will learn in this lab is one of the techniques to aggregate services using service-to-service calls.
Other possible solutions would be to use a microservices gateway or combine services using client-side logic.</p>

<h4 id="setup-a-catalog-project">1. Setup a Catalog project</h4>

<hr>

<p>Run the following commands to set up your environment for this lab and start in the right directory:</p>

<p>In the project explorer, right-click on <em>catalog</em> and then change a directory to catalog path on Terminal.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-project.dms" alt="catalog-setup" width="500px"></p>

<h4 id="examine-the-maven-project-structure">2. Examine the Maven project structure</h4>

<hr>

<p>The sample project shows the components of a basic Spring Boot project laid out in different
subdirectories according to Maven best practices.</p>

<blockquote>
  <p>Click on the catalog folder in the project explorer and navigate to see its folders and files.</p>
</blockquote>

<p>As you can see, there are some files that we have prepared for you in the project. Under <em>src/main/resources/static/index.html</em>
we have for example prepared a simple html-based UI file for you. This 
matches very well what you would get if you generated an empty project 
from the
<a href="https://start.spring.io/" target="_blank">Spring Initializr</a> web page.</p>

<p>One file that differs slightly is the <code>pom.xml</code>. Please open the and examine it a bit closer (but do not change anything
at this time)</p>

<p>As you review the content, you will notice that there are a lot of <em>TODO</em> comments. <strong>Do not remove them!</strong> These comments are used as a marker and without them, you will not be able to finish this lab.</p>

<p>Notice that we are not using the default BOM (Bill of material) that 
Spring Boot projects typically use. Instead, we are using a BOM provided
 by Red Hat as part of the <a href="http://snowdrop.me/" target="_blank">Snowdrop</a> project.</p>

<pre><code class="language-xml">&lt;dependencyManagement&gt;
&lt;dependencies&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;me.snowdrop&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-bom&lt;/artifactId&gt;
    &lt;version&gt;${spring-boot.bom.version}&lt;/version&gt;
    &lt;type&gt;pom&lt;/type&gt;
    &lt;scope&gt;import&lt;/scope&gt;
  &lt;/dependency&gt;
&lt;/dependencies&gt;
&lt;/dependencyManagement&gt;
</code></pre>

<p>We use this bill of material to make sure that we are using the version of for example Apache Tomcat that Red Hat supports.</p>

<h4 id="adding-web-apache-tomcat-to-the-application">3. Adding web (Apache Tomcat) to the application</h4>

<hr>

<p>Our application will be a web application, so we need to use a servlet container like Apache Tomcat or
Undertow. Since Red Hat offers support for Apache Tomcat (e.g., security patches, bug fixes, etc.), we will use it.</p>

<blockquote>
  <p>NOTE: Undertow is another an open source project that is maintained by Red Hat and therefore Red Hat plans to
add support for Undertow shortly.</p>
</blockquote>

<p>Because of the Red Hat BOM and access to the Red Hat maven 
repositories all we need to do to enable the supported Apache Tomcat as 
servlet container is to add the following dependency to your <em>pom.xml</em>. Add these lines at the <code>&lt;!-- TODO: Add web (tomcat) dependency here --&gt;</code> marker:</p>

<pre><code class="language-xml">        &lt;dependency&gt;
          &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
          &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>

<p>We will also make use of Java Persistance API (JPA) so we need to add the following to <em>pom.xml</em> at the <code>&lt;!-- TODO: Add jdbc dependency here --&gt;</code> marker:</p>

<pre><code class="language-xml">        &lt;dependency&gt;
          &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
          &lt;artifactId&gt;spring-boot-starter-data-jdbc&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>

<p>We will go ahead and add a bunch of other dependencies while we have 
the pom.xml open. These will be explained later. Add these at the
<code>&lt;!-- TODO: Add actuator, feign and hystrix dependency here --&gt;</code> marker:</p>

<pre><code class="language-xml">        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>

<p>Use the command palette and select ‘Build’ to build and package the 
app using Maven to make sure the changed code still compiles:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-build.dms" alt="catalog_build"></p>

<p>If it builds successfully (you will see <strong>BUILD SUCCESS</strong>), you have now successfully executed the first step in this lab.</p>

<p>Now you’ve seen how to get started with Spring Boot development on Red Hat Runtimes.</p>

<p>In next step of this lab, we will add the logic to be able to read a data from the database.</p>

<h4 id="create-domain-objects">4. Create Domain Objects</h4>

<hr>

<p>Before we create the database repository class to access the data 
it’s good practice to create test cases for the different methods that 
we will use.</p>

<p>Right-click on the <code>src/test/java/com.redhat.coolstore.service</code> package, and select <em>New &gt; Java Class</em>. Type <code>ProductRepositoryTest</code> into the dialog box and press <strong>OK</strong> which will create an empty class file.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/che-right-click.dms" alt="che" width="700px"></p>

<p>Replace the content of this new file with the below code:</p>

<pre><code class="language-java">package com.redhat.coolstore.service;

import java.util.List;
import java.util.stream.Collectors;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.test.context.junit4.SpringRunner;

import static org.assertj.core.api.Assertions.assertThat;

import com.redhat.coolstore.model.Product;


@RunWith(SpringRunner.class)
@SpringBootTest
public class ProductRepositoryTest {

    //TODO: Insert Catalog Component here

    //TODO: Insert test_readOne here

    //TODO: Insert test_readAll here

}
</code></pre>

<p>Next, inject a handle to the future repository class which will provide access to the underlying data repository. It is
injected with Spring’s <strong>@Autowired</strong> annotation which locates, instantiates, and injects runtime instances of classes automatically,
and manages their lifecycle (much like Java EE and it’s CDI feature). Add these at the <code>&lt;!-- TODO: Insert Catalog Component here --&gt;</code> marker:</p>

<pre><code class="language-java">    @Autowired
    private ProductRepository repository;
</code></pre>

<p>The <em>ProductRepository</em> should provide a method called <em>findById(String id)</em>
 that returns a product and collect that from the database. We test this
 by querying for a product with id “444434” which should have name <strong>Pebble Smart Watch</strong>. The pre-loaded data comes from the <em>src/main/resources/schema.sql</em> file.</p>

<p>Add these at the <code>&lt;!-- TODO: Insert test_readOne here --&gt;</code> marker:</p>

<pre><code class="language-java">    @Test
    public void test_readOne() {
        Product product = repository.findById("444434");
        assertThat(product).isNotNull();
        assertThat(product.getName()).as("Verify product name").isEqualTo("Pebble Smart Watch");
        assertThat(product.getQuantity()).as("Quantity should be ZERO").isEqualTo(0);
    }
</code></pre>

<p>The <em>ProductRepository</em> should also provide a methods called <em>readAll()</em>
 that returns a list of all products in the catalog. We test this by 
making sure that the list contains a “Red Fedora”, “Forge Laptop 
Sticker” and “Oculus Rift”.
Again, add these at the <code>&lt;!-- TODO: Insert test_readAll here --&gt;</code> marker:</p>

<pre><code class="language-java">    @Test
    public void test_readAll() {
        List&lt;Product&gt; productList = repository.readAll();
        assertThat(productList)
          .isNotNull()
          .isNotEmpty();
        List&lt;String&gt; names = productList.stream().map(Product::getName).collect(Collectors.toList());
        assertThat(names).contains("Red Fedora","Forge Laptop Sticker","Oculus Rift");
    }
</code></pre>

<h4 id="implement-the-database-repository">5. Implement the database repository</h4>

<hr>

<p>We are now ready to implement the database repository.</p>

<p>Use the same procedure to create a new Java Class in the <code>src/main/java/com/redhat/coolstore/service</code> package called <code>ProductRepository</code>. Replace the empty class with the following code:</p>

<pre><code class="language-java">package com.redhat.coolstore.service;

import java.util.List;

import com.redhat.coolstore.model.Product;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.jdbc.core.JdbcTemplate;
import org.springframework.jdbc.core.RowMapper;
import org.springframework.stereotype.Repository;

@Repository
public class ProductRepository {

    //TODO: Autowire the jdbcTemplate here

    //TODO: Add row mapper here

    //TODO: Create a method for returning all products

    //TODO: Create a method for returning one product

}
</code></pre>

<blockquote>
  <p>NOTE: This class is annotated with <code>@Repository</code>. This 
is a feature of Spring that makes it possible to avoid a lot of boiler 
plate code and only write the implementation details for this data 
repository. It also makes it very easy to switch to another data 
storage, like a NoSQL database.</p>
</blockquote>

<p>Spring Data provides a convenient way for us to access data without 
having to write a lot of boiler plate code. One way to do that is to use
 a <em>JdbcTemplate</em>. First we need to autowire that as a member to <em>ProductRepository</em>. Add these at the <code>&lt;!-- TODO: Autowire the jdbcTemplate here --&gt;</code> marker:</p>

<pre><code class="language-java">    @Autowired
    private JdbcTemplate jdbcTemplate;
</code></pre>

<p>The <em>JdbcTemplate</em> require that we provide a <em>RowMapper</em> so that it can map between rows in the query to Java Objects. We are going to define the <em>RowMapper</em> like this.
Add these at the <code>&lt;!-- TODO: Add row mapper here --&gt;</code> marker:</p>

<pre><code class="language-java">    private RowMapper&lt;Product&gt; rowMapper = (rs, rowNum) -&gt; new Product(
            rs.getString("itemId"),
            rs.getString("name"),
            rs.getString("description"),
            rs.getDouble("price"));
</code></pre>

<p>Now we are ready to create the methods that are used in the test. Let’s start with the <code>readAll()</code>. It should return a <code>List&lt;Product&gt;</code> and then we can write the query as <code>SELECT * FROM catalog</code> and use the rowMapper to map that into <code>Product</code> objects.
Add these at the <code>&lt;!-- TODO: Create a method for returning all products --&gt;</code> marker:</p>

<pre><code class="language-java">    public List&lt;Product&gt; readAll() {
        return this.jdbcTemplate.query("SELECT * FROM catalog", rowMapper);
    }
</code></pre>

<p>The <em>ProductRepositoryTest</em> also used another method called <em>findById(String id)</em> that should return a Product. The implementation of that method using the <em>JdbcTemplate</em> and <em>RowMapper</em> looks like this. Add these at the <code>&lt;!-- TODO: Create a method for returning one product --&gt;</code> marker:</p>

<pre><code class="language-java">    public Product findById(String id) {
        return this.jdbcTemplate.queryForObject("SELECT * FROM catalog WHERE itemId = '" + id + "'", rowMapper);
    }
</code></pre>

<p>The <em>ProductRepository</em> should now have all the components, 
but we still need to tell spring how to connect to the database. For 
local development we will use the H2 in-memory database. When deploying 
this to OpenShift we are instead going to use the PostgreSQL database, 
which matches what we are using in production.</p>

<p>The Spring Framework has a lot of sane defaults that can always seem 
magical sometimes, but basically all we have to do to setup the database
 driver is to provide some configuration values. Open <em>src/main/resources/application-default.properties</em> and add the following properties where the comment says <code>#TODO: Add database properties</code>.</p>

<pre><code class="language-java">spring.datasource.url=jdbc:h2:mem:catalog;DB_CLOSE_ON_EXIT=FALSE
spring.datasource.username=sa
spring.datasource.password=sa
spring.datasource.driver-class-name=org.h2.Driver
</code></pre>

<p>The Spring Data framework will automatically see if there is a <code>schema.sql</code> in the class path and run that when initializing.</p>

<p>Now we are ready to run the test to verify that everything works. Right-click on the <code>src/test/java/com/redhat/coolstore/service</code> package and select <em>Run Test &gt; Run JUnit Test</em>.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-test-run.dms" alt="catalog-test-run" width="600px"></p>

<p>The test should be successful and you should see green color <em>test_realAll</em>, <em>test_realOne</em> in Default Suite window.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-test-success.dms" alt="catalog-test-success" width="600px"></p>

<p>You have now successfully executed the second step in this lab.</p>

<p>Now you’ve seen how to use Spring Data to collect data from the 
database and how to use a local H2 database for development and testing.</p>

<p>In next step of this lab, we will add the logic to expose the database content from REST endpoints using JSON format.</p>

<h4 id="create-catalog-service">6. Create Catalog Service</h4>

<hr>

<p>Now you are going to create a service class. Later on the service 
class will be the one that controls the interaction with the inventory 
service, but for now it’s basically just a wrapper of the repository 
class.</p>

<p>Again, create a new class <code>CatalogService</code> in the <code>src/main/java/com/redhat/coolstore/service</code> package.</p>

<p>Replace the empty class with this code:</p>

<pre><code class="language-java">package com.redhat.coolstore.service;

import java.util.List;
import java.util.stream.Collectors;
import java.util.stream.IntStream;

//import com.redhat.coolstore.client.InventoryClient;
import com.redhat.coolstore.model.Product;

import org.json.JSONArray;
import org.json.JSONObject;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

@Service
public class CatalogService {

    @Autowired
    private ProductRepository repository;

    //TODO: Autowire Inventory Client

    public Product read(String id) {
        Product product = repository.findById(id);
        //TODO: Update the quantity for the product by calling the Inventory service
        return product;
    }

    public List&lt;Product&gt; readAll() {
        List&lt;Product&gt; productList = repository.readAll();
        //TODO: Update the quantity for the products by calling the Inventory service
        return productList;
    }

}
</code></pre>

<p>As you can see there is a number of <code>TODO</code> in the code, and later we will use these placeholders to add logic for calling the Inventory Client to get the quantity.</p>

<p>Now we are ready to create the endpoints that will expose REST 
service. Let’s again first start by creating a test case for our 
endpoint. We need two endpoints, one that exposes for GET calls to <code>/services/products</code> that will return all product in the catalog as JSON array, and the second one exposes GET calls to <code>/services/produc/{prodId}</code> which will return a single Product as a JSON Object. Let’s again start by creating a test case.</p>

<p>Create the test case by creating a new class file called <code>CatalogEndpointTest</code> in the <code>src/test/java/com/redhat/coolstore/service</code> package.</p>

<p>Add the following code to the test case and make sure to <em>review</em> it without any codes change so that you understand how it works.</p>

<pre><code class="language-java">package com.redhat.coolstore.service;

import com.redhat.coolstore.model.Inventory;
import com.redhat.coolstore.model.Product;
import io.specto.hoverfly.junit.rule.HoverflyRule;
import org.junit.ClassRule;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.boot.test.web.client.TestRestTemplate;
import org.springframework.core.ParameterizedTypeReference;
import org.springframework.http.HttpMethod;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.test.context.junit4.SpringRunner;

import java.util.List;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;

import static io.specto.hoverfly.junit.dsl.HttpBodyConverter.json;
import static io.specto.hoverfly.junit.dsl.ResponseCreators.success;
import static io.specto.hoverfly.junit.dsl.ResponseCreators.serverError;
import static io.specto.hoverfly.junit.dsl.matchers.HoverflyMatchers.startsWith;
import static org.assertj.core.api.Assertions.assertThat;
import static io.specto.hoverfly.junit.core.SimulationSource.dsl;
import static io.specto.hoverfly.junit.dsl.HoverflyDsl.service;

@RunWith(SpringRunner.class)
@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)
public class CatalogEndpointTest {

    @Autowired
    private TestRestTemplate restTemplate;

    //TODO: Add ClassRule for HoverFly Inventory simulation

    @Test
    public void test_retriving_one_proudct() {
        ResponseEntity&lt;Product&gt; response
                = restTemplate.getForEntity("/services/product/329199", Product.class);
        assertThat(response.getStatusCode()).isEqualTo(HttpStatus.OK);
        assertThat(response.getBody())
                .returns("329199",Product::getItemId)
                .returns("Forge Laptop Sticker",Product::getName)
    //TODO: Add check for Quantity
                .returns(8.50,Product::getPrice);
    }


    @Test
    public void check_that_endpoint_returns_a_correct_list() {

        ResponseEntity&lt;List&lt;Product&gt;&gt; rateResponse =
                restTemplate.exchange("/services/products",
                        HttpMethod.GET, null, new ParameterizedTypeReference&lt;List&lt;Product&gt;&gt;() {
                        });

        List&lt;Product&gt; productList = rateResponse.getBody();
        assertThat(productList).isNotNull();
        assertThat(productList).isNotEmpty();
        List&lt;String&gt; names = productList.stream().map(Product::getName).collect(Collectors.toList());
        assertThat(names).contains("Red Fedora","Forge Laptop Sticker","Oculus Rift");

        Product fedora = productList.stream().filter( p -&gt; p.getItemId().equals("329299")).findAny().get();
        assertThat(fedora)
                .returns("329299",Product::getItemId)
                .returns("Red Fedora", Product::getName)
    //TODO: Add check for Quantity
                .returns(34.99,Product::getPrice);
    }

}
</code></pre>

<p>Now we are ready to implement the <em>CatalogEndpoint</em>.</p>

<p>Start by creating a new class called <code>CatalogEndpoint</code> in the <code>src/main/java/com/redhat/coolstore/service</code> package.</p>

<p>Replace the contents with this code:</p>

<pre><code class="language-java">package com.redhat.coolstore.service;

import java.util.List;

import com.redhat.coolstore.model.Product;
import org.springframework.web.bind.annotation.*;

@RestController
@RequestMapping("/services")
public class CatalogEndpoint {
    private final CatalogService catalogService;

    public CatalogEndpoint(CatalogService catalogService) {
      this.catalogService = catalogService;
    }

    @GetMapping("/products")
    public List&lt;Product&gt; readAll() {
      return this.catalogService.readAll();
    }

    @GetMapping("/product/{id}")
    public Product read(@PathVariable("id") String id) {
      return this.catalogService.read(id);
    }
}
</code></pre>

<p>The Spring MVC Framework default uses Jackson to serialize or map 
Java objects to JSON and vice versa. Because Jackson extends upon JAX-B 
and does can automatically parse simple Java structures and parse them 
into JSON and vice verse and since our <code>Product.java</code> is very simple and only contains basic attributes we do not need to tell Jackson how to parse between Product and JSON.</p>

<p>Now you can run the <em>CatalogEndpointTest</em> and verify that it works via <strong>Run Junit Test</strong>. Right-click on the <code>CatalogEndpointTest</code> and select <em>Run Test &gt; Run JUnit Test</em>.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-endpoint-test-run.dms" alt="catalog-endpoint-test-run" width="700px"></p>

<p>The test should be successful and you should see green color <em>test_retriving_one_proudct</em>, _check_that_endpoint_returns_a_correct_list&lt;&gt; in Default Suite window.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-endpoint-test-success.dms" alt="catalog-endpoint-test-success"></p>

<p>You can also run the following command via <code>CodeReady Workspaces Terminal</code> to verify the test cases.</p>

<p><code>cd /projects/cloud-native-workshop-v2m1-labs/catalog/</code></p>

<p><code>mvn verify -Dtest=CatalogEndpointTest</code></p>

<p>Since we now have endpoints that returns the catalog we can also 
start the service and load the default page again, which should now 
return the products.</p>

<p>Start the application via CodeReady Workspaces <strong>RUN</strong> Menu:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-spring-run.dms" alt="catalog-spring-run"></p>

<p>Wait for the application to start. Then we can verify the endpoint by running the following command in Eclipse Terminal:</p>

<p><code>curl http://localhost:8081/services/products | jq</code></p>

<p>You should get a full JSON array consisting of all the products:</p>

<pre><code class="language-json">  {
    "itemId": "329299",
    "name": "Red Fedora",
    "desc": "Official Red Hat Fedora",
    "price": 34.99,
    "quantity": 0
  },
  { ... }
</code></pre>

<p>You have now successfully executed the third step in this lab.</p>

<p>Now you’ve seen how to create REST application in Spring MVC and create a simple application that returns product.</p>

<p>In the next step, we will also call another service to enrich the endpoint response with inventory status.</p>

<blockquote>
  <p>NOTE: Make sure to stop the service by closing <code>run spring-boot</code> tab window in CodeReady Workspace.</p>
</blockquote>

<h4 id="get-inventory-data">7. Get inventory data</h4>

<hr>

<p>So far our application has been kind of straight forward, but our 
monolith code for the catalog is also returning the inventory status. In
 the monolith since both the inventory data and catalog data are in the 
same database we used a <code>OneToOne</code> mapping in JPA like this:</p>

<pre><code class="language-java">@OneToOne(cascade = CascadeType.ALL,fetch=FetchType.EAGER)
@PrimaryKeyJoinColumn
private InventoryEntity inventory;
</code></pre>

<p>When redesigning our application to Microservices using domain driven
 design we have identified that Inventory and Product Catalog are two 
separate domains. However our current UI expects to retrieve data from 
both the Catalog Service and Inventory service in a singe request.</p>

<h4 id="service-interaction">Service interaction</h4>

<p>Our problem is that the user interface requires data from two services when calling the REST service on <code>/services/products</code>. There are multiple ways to solve this like:</p>

<p><strong>I. Client Side integration</strong> - We could extend our UI to first call <code>/services/products</code> and then for each product item call <code>/services/inventory/{prodId}</code>
 to get the inventory status and then combine the result in the web 
browser. This would be the least intrusive method, but it also means 
that if we have 100 of products the client will make 101 request to the 
server. If we have a slow internet connection this may cause issues.</p>

<p><strong>II. Microservices Gateway</strong> - Creating a gateway in-front of the <code>Catalog Service</code>
 that first calls the Catalog Service and then based on the response 
calls the inventory is another option. This way we can avoid lots of 
calls from the client to the server. <a href="http://camel.apache.org/" target="_blank">Apache Camel</a>
 provides nice capabilities to do this and if you are interested to 
learn more about this, please checkout the Coolstore Microservices 
example: <a href="http://github.com/jbossdemocentral/coolstore-microservice" target="_blank">Here</a></p>

<p><strong>III. Service-to-Service</strong> - Depending on use-case and 
preferences another solution would be to do service-to-service calls 
instead. In our case means that the Catalog Service would call the 
Inventory service using REST to retrieve the inventory status and 
include that in the response.</p>

<p>There are no right or wrong answers here, but since this is a 
workshop on application modernization using Red Hat Runtimes we will not
 choose option I or II here. Instead we are going to use option III and 
extend our Catalog to call the Inventory service.</p>

<h4 id="extending-the-test">8. Extending the test</h4>

<hr>

<p>In the <a href="https://en.wikipedia.org/wiki/Test-driven_development" target="_blank">Test-Driven Development</a> style, let’s first extend our test to test the Inventory functionality (which doesn’t exist).</p>

<p>Open <em>src/test/java/com/redhat/coolstore/service/CatalogEndpointTest.java</em> again.</p>

<p>Now at the markers <strong>//TODO: Add check for Quantity</strong> add the following line:</p>

<p><code>                .returns(9999,Product::getQuantity)</code></p>

<p>And add it to the second test as well at the remaining <em>//TODO: Add check for Quantity</em> marker:</p>

<p><code>                .returns(9999,Product::getQuantity)</code></p>

<p>Now you can run the <em>CatalogEndpointTest</em> and verify that it <strong>fails</strong> via <em>Run Junit Test</em>:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-endpoint-test-run.dms" alt="catalog-endpoint-test-run" width="700px"></p>

<p>The test <em>should fail</em> and you should see red color <strong>test_retriving_one_proudct</strong>, <strong>check_that_endpoint_returns_a_correct_list</strong> in Default Suite window.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-endpoint-test-failure.dms" alt="catalog-endpoint-test-failure"></p>

<p>The test fails because we are trying to call the Inventory service which is not runninmg.</p>

<p>We will soon implement the code to call the inventory service, but 
first
we need a away to test this service without having to rely on the 
inventory services to be up and running. For that we are going to use an
 API Simulator
called <a href="http://hoverfly.io/" target="_blank">HoverFly</a> and 
particular it’s capability to simulate remote APIs. HoverFly is very 
convenient to use with Unit test and all we have to do is
to add a <strong>ClassRule</strong> that will simulate all calls to inventory. Open the file to insert the
code at the <code>//TODO: Add ClassRule for HoverFly Inventory simulation</code> marker in <em>CatalogEndpointTest</em> class:</p>

<pre><code class="language-java">    @ClassRule
    public static HoverflyRule hoverflyRule = HoverflyRule.inSimulationMode(dsl(
            service("inventory:8080")
    //                    .andDelay(2500, TimeUnit.MILLISECONDS).forMethod("GET")
                    .get(startsWith("/services/inventory"))
    //                    .willReturn(serverError())
                    .willReturn(success("[{\"itemId\":\"329199\",\"quantity\":9999}]", "application/json"))

    ));
</code></pre>

<p>This <em>ClassRule</em> means that if our tests are trying to call 
our inventory url, HoverFly will intercept this and respond with our 
hard coded response instead.</p>

<p>We will soon use the <code>// commented-out</code> lines, so keep them in there!</p>

<h4 id="implementing-the-inventory-client">9. Implementing the Inventory Client</h4>

<hr>

<p>Since we now have a nice way to test our service-to-service 
interaction we can now create the client that calls the Inventory. 
Netflix has provided some nice extensions to the Spring Framework that 
are mostly captured in the Spring Cloud project, however Spring Cloud is
 mainly focused on Pivotal Cloud Foundry and because of that Red Hat and
 others have contributed Spring Cloud Kubernetes to the Spring Cloud 
project, which enables the same functionallity for Kubernetes based 
platforms like OpenShift.</p>

<p>The inventory client will use a Netflix project called <em>Feign</em>,
 which provides a nice way to avoid having to write boilerplate code. 
Feign also integrate with Hystrix which gives us capability to Circuit 
Break calls that don’t work. We will discuss this more later, but let’s 
start with the implementation of the Inventory Client. Using Feign all 
we have todo is to create a interface that details which parameters and 
return type we expect, annotate it with    <code>@RequestMapping</code> and provide some details and then annotate the interface with <code>@Feign</code> and provide it with a name.</p>

<p>Create the <code>InventoryClient</code> class in the <code>src/main/java/com/redhat/coolstore/client/</code> package in the project explorer.</p>

<p>Add the following code to the file:</p>

<pre><code class="language-java">package com.redhat.coolstore.client;

import feign.hystrix.FallbackFactory;
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.http.MediaType;
import org.springframework.stereotype.Component;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestMethod;

@FeignClient(name="inventory")
public interface InventoryClient {

    @RequestMapping(method = RequestMethod.GET, value = "/services/inventory/{itemId}", consumes = {MediaType.APPLICATION_JSON_VALUE})
    String getInventoryStatus(@PathVariable("itemId") String itemId);

    //TODO: Add Fallback factory here

}
</code></pre>

<p>There is one more thing that we need to do which is to tell Feign 
where the inventory service is running. Before that notice that we are 
setting the <code>@FeignClient(name="inventory")</code>.</p>

<p>Open the `src/main/resources/application-default.properties file.</p>

<p>Add these properties to it at the <code>#TODO: Configure netflix libraries</code> marker:</p>

<pre><code class="language-java">inventory.ribbon.listOfServers=inventory:8080
feign.hystrix.enabled=true
</code></pre>

<p>By setting <em>inventory.ribbon.listOfServers</em> we are hard coding the actual URL of the service to <strong>inventory:8080</strong>.
 If we had multiple servers we could also add those using a comma. 
However using Kubernetes there is no need to have multiple endpoints 
listed here since Kubernetes has a concept of <em>Services</em> that 
will internally route between multiple instances of the same service. 
Later on we will update this value to reflect our URL when deploying to 
OpenShift.</p>

<p>Now that we have a client we can make use of it in our <em>CatalogService</em>.</p>

<p>Open <em>src/main/java/com/redhat/coolstore/service/CatalogService.java</em></p>

<p>And autowire (e.g. inject) the client into it by inserting this at the <code>//TODO: Autowire Inventory Client</code> marker:</p>

<pre><code class="language-java">    @Autowired
    private InventoryClient inventoryClient;
</code></pre>

<p>Next, update the <em>read(String id)</em> method at the comment <code>//TODO: Update the quantity for the product by calling the Inventory service</code> add the following:</p>

<pre><code class="language-java">        JSONArray jsonArray = new JSONArray(inventoryClient.getInventoryStatus(product.getItemId()));
        List&lt;String&gt; quantity = IntStream.range(0, jsonArray.length())
            .mapToObj(index -&gt; ((JSONObject)jsonArray.get(index))
            .optString("quantity")).collect(Collectors.toList());
        product.setQuantity(Integer.parseInt(quantity.get(0)));
</code></pre>

<p>Also, don’t forget to add the import statement by un-commenting the import statement <strong>//import com.redhat.coolstore.client.InventoryClient</strong> near the top</p>

<pre><code class="language-java">import com.redhat.coolstore.client.InventoryClient;
</code></pre>

<p>Also in the <em>readAll()</em> method replace the comment <code>//TODO: Update the quantity for the products by calling the Inventory service</code> with the following:</p>

<pre><code class="language-java">        productList.forEach(p -&gt; {
          JSONArray jsonArray = new JSONArray(this.inventoryClient.getInventoryStatus(p.getItemId()));
          List&lt;String&gt; quantity = IntStream.range(0, jsonArray.length())
            .mapToObj(index -&gt; ((JSONObject)jsonArray.get(index))
            .optString("quantity")).collect(Collectors.toList());
          p.setQuantity(Integer.parseInt(quantity.get(0)));
        });
</code></pre>

<blockquote>
  <p>NOTE: Class <code>JSONArray</code> is an ordered sequence of 
values. Its external text form is a string wrapped in square brackets 
with commas separating the values. The internal form is an object having
 get and opt methods for accessing the values by index, and element 
methods for adding or replacing values.</p>
</blockquote>

<p>Now you can run the <em>CatalogEndpointTest</em> and verify that it works via <strong>Run Junit Test</strong>:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-endpoint-test-run.dms" alt="catalog-endpoint-test-run" width="700px"></p>

<p>The test should be successful and you should see green color <strong>test_retriving_one_proudct</strong>, <strong>check_that_endpoint_returns_a_correct_list</strong> in Default Suite window.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-endpoint-test-success.dms" alt="catalog-endpoint-test-success"></p>

<p>So even if we don’t have any inventory service running we can still run our test. However to actually run the service using <code>mvn spring-boot:run</code> we need to have an inventory service or the calls to <code>/services/products/</code> will fail. We will fix this in the next step.</p>

<h5 id="congratulations">Congratulations!</h5>
<p>You now have the framework for retrieving products from the product catalog and enriching the data with inventory data from
an external service. But what if that external inventory service does not respond? That’s the topic for the next step.</p>

<h4 id="create-a-fallback-for-inventory">10. Create a fallback for inventory</h4>

<hr>

<p>In the previous step we added a client to call the Inventory service.
 Services calling services is a common practice in Microservices 
Architecture, but as we add more and more services the likelihood of a 
problem increases dramatically. Even if each service has 99.9% update, 
if we have 100 of services our estimated up time will only be ~90%. We 
therefor need to plan for failures to happen and our application logic 
has to consider that dependent services are not responding.</p>

<p>In the previous step we used the Feign client from the Netflix cloud native libraries to avoid having to write
boilerplate code for doing a REST call. However Feign also have another good property which is that we easily create
fallback logic. In this case we will use static inner class since we want the logic for the fallback to be part of the
Client and not in a separate class.</p>

<p>Open: <em>src/main/java/com/redhat/coolstore/client/InventoryClient.java</em></p>

<p>And paste this into it at the <code>//TODO: Add Fallback factory here</code> marker:</p>

<pre><code class="language-java">    //TODO: Add Callback Factory Component
    @Component
    class InventoryClientFallbackFactory implements FallbackFactory&lt;InventoryClient&gt; {
      @Override
      public InventoryClient create(Throwable cause) {
        return itemId -&gt; "[{'quantity':-1}]";
      }
    }
</code></pre>

<p>After creating the fallback factory all we have todo is to tell Feign
 to use that fallback in case of an issue, by adding the fallbackFactory
 property to the <code>@FeignClient</code> annotation. and replace the existing <code>@FeignClient(name="inventory")</code> line with this line:</p>

<pre><code class="language-java">@FeignClient(name="inventory",fallbackFactory = InventoryClient.InventoryClientFallbackFactory.class)
</code></pre>

<h4 id="test-the-fallback">11. Test the Fallback</h4>

<hr>

<p>Now let’s see if we can test the fallback. Optimally we should create
 a different test that fails the request and then verify the fallback 
value, however because we are limited in time we are just going to 
change our test so that it returns a server error and then verify that 
the test fails.</p>

<p>Open <em>src/test/java/com/redhat/coolstore/service/CatalogEndpointTest.java</em> and change the following lines:</p>

<pre><code>@ClassRule
public static HoverflyRule hoverflyRule = HoverflyRule.inSimulationMode(dsl(
        service("inventory:8080")
//                    .andDelay(2500, TimeUnit.MILLISECONDS).forMethod("GET")
                .get(startsWith("/services/inventory"))
//                    .willReturn(serverError())
                .willReturn(success("[{\"itemId\":\"329199\",\"quantity\":9999}]", "application/json"))

));
</code></pre>

<p>TO</p>

<pre><code>@ClassRule
public static HoverflyRule hoverflyRule = HoverflyRule.inSimulationMode(dsl(
        service("inventory:8080")
//                    .andDelay(2500, TimeUnit.MILLISECONDS).forMethod("GET")
                .get(startsWith("/services/inventory"))
                .willReturn(serverError())
//                    .willReturn(success("[{\"itemId\":\"329199\",\"quantity\":9999}]", "application/json"))

));
</code></pre>

<p>Notice that the Hoverfly Rule will now return <code>serverError</code> for all requests to inventory.</p>

<p>Now you can run the <em>CatalogEndpointTest</em> and verify that it <strong>fails</strong> via <strong>Run Junit Test</strong>:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-endpoint-test-run.dms" alt="catalog-endpoint-test-run" width="700px"></p>

<p>The test <em>should fail</em> and you _should see red color <code>test_retriving_one_proudct_, _check_that_endpoint_returns_a_correct_list</code> in Default Suite window.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-endpoint-test-failure.dms" alt="catalog-endpoint-test-failure"></p>

<p>So since even if our inventory service fails we are still returning 
inventory quantity -1. The test fails because we are expecting the 
quantity to be 9999.</p>

<p>Change back the class rule by re-commenting out the <em>.willReturn(serverError())</em> line so that we don’t fail the tests like this:</p>

<pre><code>@ClassRule
public static HoverflyRule hoverflyRule = HoverflyRule.inSimulationMode(dsl(
        service("inventory:8080")
//                    .andDelay(2500, TimeUnit.MILLISECONDS).forMethod("GET")
                .get(startsWith("/services/inventory"))
//                    .willReturn(serverError())
                .willReturn(success("[{\"itemId\":\"329199\",\"quantity\":9999}]", "application/json"))

));
</code></pre>

<p>Make sure the test works again by re-running the <code>CatalogEndpointTest</code> JUnit Test.</p>

<h4 id="slow-running-services">12. Slow running services</h4>

<hr>

<p>Having fallbacks is good but that also requires that we can correctly
 detect when a dependent services isn’t responding correctly. Besides 
from not responding a service can also respond slowly causing our 
services to also respond slow. This can lead to cascading issues that is
 hard to debug and pinpoint issues with. We should therefore also have 
sane defaults for our services. You can add defaults by adding it to the
 configuration.</p>

<p>Open <em>src/main/resources/application-default.properties</em></p>

<p>And add this line to it at the <strong>#TODO: Set timeout to for inventory to 500ms</strong> marker:</p>

<pre><code class="language-java">hystrix.command.inventory.execution.isolation.thread.timeoutInMilliseconds=500
</code></pre>

<p>Open <em>src/test/java/com/redhat/coolstore/service/CatalogEndpointTest.java</em> and un-comment the <strong>.andDelay(2500, TimeUnit.MILLISECONDS).forMethod(“GET”)</strong></p>

<p>Now you can run the <em>CatalogEndpointTest</em> and verify that it <strong>fails</strong> via <strong>Run Junit Test</strong>:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-endpoint-test-run.dms" alt="catalog-endpoint-test-run" width="700px"></p>

<p>The test <em>should fail</em> and you should see red color <code>test_retriving_one_proudct</code>, <code>check_that_endpoint_returns_a_correct_list</code> in Default Suite window.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-endpoint-test-failure.dms" alt="catalog-endpoint-test-failure"></p>

<p>This shows that the timeout works nicely. However, since we want our test to be successful <strong>you should now comment out <code>.andDelay(2500, TimeUnit.MILLISECONDS).forMethod("GET")</code></strong> again and then verify that the test works by re-running the JUnit test.</p>

<h4 id="congratulations-1">Congratulations!</h4>
<p>You have now successfully executed the fourth step in this lab.
In this step you’ve learned how to add Fallback logic to your class and how to add timeout to service calls.
In the next step we now test our service locally before we deploy it to OpenShift.</p>

<h4 id="test-locally">13. Test Locally</h4>

<hr>

<p>As you have seen in previous steps, using the Spring Boot maven plugin (predefined in <em>pom.xml</em>), you can conveniently run the application locally and test the endpoint.</p>

<p>Start the application via CodeReady Workspaces <strong>RUN</strong> Menu:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-spring-run.dms" alt="catalog-spring-run"></p>

<p>Wait for the application to start. Then we can verify the endpoint by running the following command in Eclipse Terminal:</p>

<p><code>curl http://localhost:8081/services/product/329299 ; echo</code></p>

<p>You would see a JSON response like this:</p>

<pre><code class="language-json">{"itemId":"329299","name":"Red Fedora","desc":"Official Red Hat Fedora","price":34.99,"quantity":-1}%
</code></pre>

<blockquote>
  <p>NOTE: Since we do not have an inventory service running locally the
 value for the quantity is -1, which matches the fallback value that we 
have configured.</p>
</blockquote>

<p>The REST API returned a JSON object representing the inventory count for this product. Well done!</p>

<blockquote>
  <p>NOTE: Make sure to stop the service by closing run spring-boot tab window in CodeReady Workspace.</p>
</blockquote>

<p>You have now successfully created your the Catalog service using Spring Boot and implemented basic REST
API on top of the product catalog database. You have also learned how to deal with service failures.</p>

<p>In next step of this lab we will deploy our application to OpenShift Container Platform and then start
adding additional features to take care of various aspects of cloud native microservice development.</p>

<h4 id="create-the-openshift-project">14. Create the OpenShift project</h4>

<hr>

<p>We have already deployed our coolstore monolith and inventory to 
OpenShift. In this step we will deploy our new Catalog microservice for 
our CoolStore application,
so let’s create a separate project to house it and keep it separate from
 our monolith and our other microservices.</p>

<p>Click on the name of the <strong>userXX-catalog</strong> project:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/create_new_catalog.dms" alt="create_new"></p>

<p>This will take you to the project overview. There’s nothing there yet, but that’s about to change.</p>

<p>Next, we’ll deploy your new microservice to OpenShift.</p>

<h4 id="deploy-to-openshift">15. Deploy to OpenShift</h4>

<hr>

<p>Now that you’ve logged into OpenShift, let’s deploy our new catalog microservice:</p>

<p>Our production catalog microservice will use an external database (PostgreSQL) to house inventory data.
First, deploy a new instance of PostgreSQL by executing via CodeReady Workspaces Terminal:</p>

<p><code>oc new-project userXX-catalog</code></p>

<pre><code class="language-shell">oc new-app -e POSTGRESQL_USER=catalog \
             -e POSTGRESQL_PASSWORD=mysecretpassword \
             -e POSTGRESQL_DATABASE=catalog \
             openshift/postgresql:10 \
             --name=catalog-database
</code></pre>

<p>This will deploy the database to our new project.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog_posgresql.dms" alt="catalog_posgresql"></p>

<p>You can also check if the deployment is complete via CodeReady Workspaces Terminal:</p>

<p><code>oc rollout status -w dc/catalog-database</code></p>

<h4 id="update-configuration">16. Update configuration</h4>

<hr>

<p>Open the file <em>src/main/resources/application-default.properties</em> in CodeReady Workspace.</p>

<p>Comment the local variables and add a remote variables. You can 
replace the whole contents with the following variables to the file:</p>

<ul>
  <li>You have to replace <strong>userXX</strong> with your username in <code>inventory.ribbon.listOfServers=inventory-quarkus.userXX-inventory.svc.cluster.local:8080</code>.</li>
</ul>

<pre><code class="language-java"># Tomcat port - To avoid port conflict we set this to 8081 in the local environment
#server.port=8081

#TODO: Add database properties
#spring.datasource.url=jdbc:h2:mem:catalog;DB_CLOSE_ON_EXIT=FALSE
#spring.datasource.username=sa
#spring.datasource.password=sa
#spring.datasource.driver-class-name=org.h2.Driver

#TODO: Configure netflix libraries
#inventory.ribbon.listOfServers=inventory:8080
feign.hystrix.enabled=true

#TODO: Set timeout to for inventory to 500ms
hystrix.command.inventory.execution.isolation.thread.timeoutInMilliseconds=500

server.port=8080
spring.datasource.url=jdbc:postgresql://catalog-database:5432/catalog
spring.datasource.username=catalog
spring.datasource.password=mysecretpassword
spring.datasource.driver-class-name=org.postgresql.Driver

inventory.ribbon.listOfServers=inventory-quarkus.userXX-inventory.svc.cluster.local:8080

spring.datasource.initialization-mode=always
</code></pre>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog_changed_properties.dms" alt="catalog_posgresql"></p>

<h4 id="build-and-deploy">17. Build and Deploy</h4>

<hr>

<p>Build and deploy the project using the following command, which will 
use the maven plugin to deploy via CodeReady Workspaces Terminal:</p>

<p><code>cd /projects/cloud-native-workshop-v2m1-labs/catalog/</code></p>

<p><code>mvn clean package spring-boot:repackage -DskipTests</code></p>

<p>The build and deploy may take a minute or two. Wait for it to complete. You should see a <strong>BUILD SUCCESS</strong> at the
end of the build output.</p>

<p>Then deploy the project using the following command, which will use 
the maven plugin to deploy via CodeReady Workspaces Terminal:</p>

<p><code>oc new-build 
registry.access.redhat.com/redhat-openjdk-18/openjdk18-openshift:1.5 
--binary --name=catalog-springboot -l app=catalog-springboot</code></p>

<p>This build uses the new <a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_middleware_for_openshift/3/html/red_hat_java_s2i_for_openshift/index" target="_blank">Red Hat OpenJDK Container Image</a>, providing foundational software needed to run Java applications, while staying at a reasonable size.</p>

<p>And then start and watch the build, which will take about a minute to complete:</p>

<p><code>oc start-build catalog-springboot --from-file=target/catalog-1.0.0-SNAPSHOT.jar --follow</code></p>

<p>Once the build is done, we’ll deploy it as an OpenShift application:</p>

<p><code>oc new-app catalog-springboot</code></p>

<p>and expose your service to the world:</p>

<p><code>oc expose service catalog-springboot</code></p>

<p>Finally, make sure it’s actually done rolling out:</p>

<p><code>oc rollout status -w dc/catalog-springboot</code></p>

<p>Wait for that command to report replication controller “catalog-springboot-1” successfully rolled out before continuing.</p>

<blockquote>
  <p>NOTE: Even if the rollout command reports success the application 
may not be ready yet and the reason for that is that we currently don’t 
have any liveness check configured, but we will add that in the next 
steps.</p>
</blockquote>

<p>And now we can access using curl once again to find a certain inventory:</p>

<p><code>export URL="http://$(oc get route | grep catalog | awk '{print $2}')"</code></p>

<p><code>curl $URL/services/product/329299 ; echo</code></p>

<p>The expected result data is here:</p>

<p><code>{"itemId":"329299","name":"Red Fedora","desc":"Official Red Hat Fedora","price":34.99,"quantity":736}</code></p>

<blockquote>
  <p><strong>NOTE</strong> if you do not get the expected output, make sure you replaced <code>userXX</code> in the <code>application-default.properties</code> file! If you forgot to do this, go back and make the change and re-build using the previous <code>mvn</code> command and re-deploy to OpenShift with the previous <code>oc start-build</code> command.</p>
</blockquote>

<p>So now <strong>Catalog</strong> service is deployed to OpenShift. You can also see it in the Project Status in the OpenShift Console
with running in 1 pod, along with the Postgres database pod.</p>

<h4 id="access-the-application-running-on-openshift">18. Access the application running on OpenShift</h4>

<hr>

<p>This sample project includes a simple UI that allows you to access the Inventory API. This is the same
UI that you previously accessed outside of OpenShift which shows the CoolStore inventory. Click on the
route URL at <strong>Networking &gt; Routes</strong> in ARO web console to access the sample UI.</p>

<blockquote>
  <p>You can also access the application through the link on Resources tab in the Project Status page.</p>
</blockquote>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-route-link.dms" alt="catalog-route-link"></p>

<p>The UI will refresh the catalog table every 2 seconds, as before.</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-sample-ui.dms" alt="catalog-sample-ui"></p>

<blockquote>
  <p>NOTE: Since we previously have a inventory service running you 
should now see the actual quantity value and not the fallback value of 
-1.</p>
</blockquote>

<p><code>Congratulations!</code> You have deployed the Catalog service 
as a microservice which in turn calls into the Inventory service to 
retrieve inventory data.</p>

<h4 id="strangling-the-monolith">19. Strangling the monolith</h4>

<hr>

<p>So far we haven’t started <a href="https://www.martinfowler.com/bliki/StranglerApplication.html" target="_blank">strangling the monolith</a>.
 To do this we are going to make use of routing capabilities in 
OpenShift. Each external request coming into OpenShift (unless using 
ingress, which we are not) will pass through a route. In our monolith 
the web page uses client side REST calls to load different parts of 
pages.</p>

<p>For the home page the product list is loaded via a REST call to *http://<monolith-hostname>/services/products*.
 At the moment calls to that URL will still hit product catalog in the 
monolith. Now we will route these calls to our newly created catalog 
services instead and end up with something like:</monolith-hostname></p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog-goal.dms" alt="Greeting" width="700px"></p>

<p>Follow the steps below to create <strong>Cross-origin resource sharing (CORS)</strong>
 based route. CORS is a mechanism that allows restricted resources on a 
web page to be requested from another domain outside the domain from 
which the first resource was served.</p>

<p>Create <strong>CORSProvider</strong> class in <em>src/main/java/com/redhat/coolstore</em> of <strong>inventory</strong> project to allow restricted resources on a <em>catalog</em> service. Copy the following all codes in the class:</p>

<pre><code class="language-java">package com.redhat.coolstore;

import org.jboss.resteasy.plugins.interceptors.CorsFilter;

import javax.ws.rs.core.Feature;
import javax.ws.rs.core.FeatureContext;
import javax.ws.rs.ext.Provider;

@Provider
public class CORSProvider implements Feature {
    @Override
    public boolean configure(FeatureContext context) {
        CorsFilter filter = new CorsFilter();
        filter.getAllowedOrigins().add("*");
        filter.setAllowedMethods("GET, POST, DELETE, OPTIONS, HEAD");
        filter.setAllowedHeaders("accept, content-type, origin");
        context.register(filter);
        return true;
    }
}
</code></pre>

<p>Repackage the <strong>inventory</strong> application via clicking on <strong>Package for OpenShift</strong> in Commands Palette:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/quarkus-dev-run-packageforOcp.dms" alt="codeready-workspace-maven"></p>

<p>Restart and watch the build, which will take about a minute to complete. Replace your username with <strong>userXX</strong>:</p>

<p><code>cd /projects/cloud-native-workshop-v2m1-labs/inventory/</code></p>

<p><code>oc start-build inventory-quarkus --from-file target/*-runner.jar --follow -n userXX-inventory</code></p>

<p>Once the build is done, the inventory pod will be deployed automatically via DeploymentConfig Trigger in OpenShift.</p>

<p>Open <strong>CatalogEndpoint</strong> class in <em>src/main/java/com/redhat/coolstore/service</em> of <strong>catalog</strong> project to allow restricted resources on a <em>product</em> page of the monolith application. Add <em>@CrossOrigin</em> annotation on <em>CatalogEndpoint</em> class:</p>

<pre><code class="language-java">@RestController
@CrossOrigin
@RequestMapping("/services")
</code></pre>

<p>Repackage the project using the following command, which will use the maven plugin to deploy via CodeReady Workspaces Terminal:</p>

<p><code>cd /projects/cloud-native-workshop-v2m1-labs/catalog/</code></p>

<p><code>mvn clean package spring-boot:repackage -DskipTests</code></p>

<p>The build and deploy may take a minute or two. Wait for it to complete. You should see a <strong>BUILD SUCCESS</strong> at the
end of the build output.</p>

<p>Restart and watch the build, which will take about a minute to complete. Replace your username with <strong>userXX</strong>:</p>

<p><code>cd /projects/cloud-native-workshop-v2m1-labs/catalog/</code></p>

<p><code>oc start-build catalog-springboot --from-file=target/catalog-1.0.0-SNAPSHOT.jar --follow -n userXX-catalog</code></p>

<p>Once the build is done, the catalog pod will be deployed automatically via DeploymentConfig Trigger in OpenShift.</p>

<p>Let’s update the catalog endpoint in monolith application. Copy the route URL of catalog service using following <strong>oc</strong> command in CodeReady Workspaces Terminal. Replace your username with <strong>userXX</strong>:</p>

<p><code>echo "http://$(oc get route -n userXX-catalog | grep catalog | awk '{print $2}')"</code></p>

<p>In the <strong>monolith</strong> project, open <code>catalog.js</code> in <code>src/main/webapp/app/services</code> and add a line as shown in the image to define the value of <code>baseUrl</code>.</p>

<p><code>baseUrl="YOUR_CATALOG_ROUTE_URL/services/products";</code></p>

<blockquote>
  <p>Replace <code>YOUR_CATALOG_ROUTE_URL</code> with the URL emitted from the previous <code>echo</code> command</p>
</blockquote>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/catalog_js_strangler.dms" alt="strangler"></p>

<p>Rebuild the project in CodeReady Workspaces Terminal:</p>

<p><code>cd /projects/cloud-native-workshop-v2m1-labs/monolith/</code></p>

<p><code>mvn clean package -Popenshift</code></p>

<p>Wait for the build to finish and the <code>BUILD SUCCESS</code> message!</p>

<p>Restart and watch the build, which will take about a minute to complete. Replace your username with <strong>userXX</strong>:</p>

<p><code>oc start-build coolstore --from-file=deployments/ROOT.war --follow -n userXX-coolstore-dev</code></p>

<p>Once the build is done, the coolstore pod will be deployed 
automatically via DeploymentConfig Trigger in OpenShift. Ensure it’s 
rolled out:</p>

<p><code>oc rollout status -w dc/coolstore -n userXX-coolstore-dev</code> (replace <code>userXX</code> with your username)</p>

<h4 id="test-the-ui">20. Test the UI</h4>

<hr>

<p>Open the monolith UI at by selecting the <code>userXX-coolstore-dev</code> project in the ARO web console, navigate to <em>Networking &gt; Routes</em> and click on the link to the monolith UI.</p>

<p>Observe that the new catalog is being used along with the monolith:</p>

<p><img src="The%20Containers%20and%20Cloud-Native%20Roadshow%20Dev%20Track%20-%20Module%201_files/coolstore-web.dms" alt="Greeting"></p>

<p>The screen will look the same, but notice that the earlier product <em>Atari 2600 Joystick</em> is now gone,
as it has been removed in our new catalog microservice.</p>

<blockquote>
  <p>Note: If the web page is still same then you should clean cookies and caches in your web browser.</p>
</blockquote>

<h5 id="congratulations-2">Congratulations!</h5>
<p>You have now successfully begun to <em>strangle</em> the monolith. Part of the monolith’s functionality (Inventory and Catalog) are
now implemented as microservices.</p>

<h5 id="summary">Summary</h5>

<hr>

<p>In this lab you learned a bit more about what Spring Boot and how it can be used together with OpenShift and OpenShift
Kubernetes.</p>

<p>You created a new product catalog microservice representing functionality previously implemented in the monolithic
CoolStore application. This new service also communicates with the inventory service to retrieve the inventory status
for each product.</p>

        <hr>
    </div>
  </div>
</main>



</body></html>
